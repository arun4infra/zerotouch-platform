version: v1alpha1 # Indicates the schema used to decode the contents.
debug: false # Enable verbose logging to the console.
persist: true
# Provides machine specific configuration options.
machine:
    type: controlplane # Defines the role of the machine within the cluster.
    token: 60qwji.s4g72kd8ed307b4d # The `token` is used by a machine to join the PKI of the cluster.
    # The root certificate authority of the PKI.
    ca:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJQakNCOGFBREFnRUNBaEFvS2FnVFNVL2hzTjVheUVvdzRXTmxNQVVHQXl0bGNEQVFNUTR3REFZRFZRUUsKRXdWMFlXeHZjekFlRncweU5URXhNalF3T1RBNU5UTmFGdzB6TlRFeE1qSXdPVEE1TlROYU1CQXhEakFNQmdOVgpCQW9UQlhSaGJHOXpNQ293QlFZREsyVndBeUVBVkRPTjhSM2hUVktIMldzdlFJbyt3NU1hbit0cVdFZHN6eTlQClpIRkh5K1NqWVRCZk1BNEdBMVVkRHdFQi93UUVBd0lDaERBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUkKS3dZQkJRVUhBd0l3RHdZRFZSMFRBUUgvQkFVd0F3RUIvekFkQmdOVkhRNEVGZ1FVTGFPaTFaTDRBZDlkYUczZgphdVdLL0Z4a2NSc3dCUVlESzJWd0EwRUE0RFRrd0xyM1hEcE93bmNnOEloUWZBZHNqc0dzU2JUZVZzeEVVK0hvCkU0eVZ4SHdLWTdmVW8vMjRMSzlYc25LUmppZGhNWTI3NGQ0Z3FEaHI2NXNSQ0E9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFRDI1NTE5IFBSSVZBVEUgS0VZLS0tLS0KTUM0Q0FRQXdCUVlESzJWd0JDSUVJRXBoSTNibVB0eHNtY2VnOFg3bWhDeVJhL0RvK2lHbXlSOGhWSlYvOXUvbwotLS0tLUVORCBFRDI1NTE5IFBSSVZBVEUgS0VZLS0tLS0K
    # Extra certificate subject alternative names for the machine's certificate.
    certSANs: []
    #   # Uncomment this to enable SANs.
    #   - 10.0.0.10
    #   - 172.16.0.10
    #   - 192.168.0.10

    # Used to provide additional options to the kubelet.
    kubelet:
        image: ghcr.io/siderolabs/kubelet:v1.34.1 # The `image` field is an optional reference to an alternative kubelet image.
        defaultRuntimeSeccompProfileEnabled: true # Enable container runtime default Seccomp profile.
        disableManifestsDirectory: true # The `disableManifestsDirectory` field configures the kubelet to get static pod manifests from the /etc/kubernetes/manifests directory.
        
        # # The `ClusterDNS` field is an optional reference to an alternative kubelet clusterDNS ip list.
        # clusterDNS:
        #     - 10.96.0.10
        #     - 169.254.2.53

        # # The `extraArgs` field is used to provide additional flags to the kubelet.
        # extraArgs:
        #     key: value

        # # The `extraMounts` field is used to add additional mounts to the kubelet container.
        # extraMounts:
        #     - destination: /var/lib/example # Destination is the absolute path where the mount will be placed in the container.
        #       type: bind # Type specifies the mount kind.
        #       source: /var/lib/example # Source specifies the source path of the mount.
        #       # Options are fstab style mount options.
        #       options:
        #         - bind
        #         - rshared
        #         - rw

        # # The `extraConfig` field is used to provide kubelet configuration overrides.
        # extraConfig:
        #     serverTLSBootstrap: true

        # # The `KubeletCredentialProviderConfig` field is used to provide kubelet credential configuration.
        # credentialProviderConfig:
        #     apiVersion: kubelet.config.k8s.io/v1
        #     kind: CredentialProviderConfig
        #     providers:
        #         - apiVersion: credentialprovider.kubelet.k8s.io/v1
        #           defaultCacheDuration: 12h
        #           matchImages:
        #             - '*.dkr.ecr.*.amazonaws.com'
        #             - '*.dkr.ecr.*.amazonaws.com.cn'
        #             - '*.dkr.ecr-fips.*.amazonaws.com'
        #             - '*.dkr.ecr.us-iso-east-1.c2s.ic.gov'
        #             - '*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov'
        #           name: ecr-credential-provider

        # # The `nodeIP` field is used to configure `--node-ip` flag for the kubelet.
        # nodeIP:
        #     # The `validSubnets` field configures the networks to pick kubelet node IP from.
        #     validSubnets:
        #         - 10.0.0.0/8
        #         - '!10.0.0.3/32'
        #         - fdc7::/16
    # Provides machine specific network configuration options.
    network: {}
    # # `interfaces` is used to define the network interface configuration.
    # interfaces:
    #     - interface: enp0s1 # The interface name.
    #       # Assigns static IP addresses to the interface.
    #       addresses:
    #         - 192.168.2.0/24
    #       # A list of routes associated with the interface.
    #       routes:
    #         - network: 0.0.0.0/0 # The route's network (destination).
    #           gateway: 192.168.2.1 # The route's gateway (if empty, creates link scope route).
    #           metric: 1024 # The optional metric for the route.
    #       mtu: 1500 # The interface's MTU.
    #       
    #       # # Picks a network device using the selector.

    #       # # select a device with bus prefix 00:*.
    #       # deviceSelector:
    #       #     busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       # # select a device with mac address matching `*:f0:ab` and `virtio` kernel driver.
    #       # deviceSelector:
    #       #     hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #     driver: virtio_net # Kernel driver, supports matching by wildcard.
    #       # # select a device with bus prefix 00:*, a device with mac address matching `*:f0:ab` and `virtio` kernel driver.
    #       # deviceSelector:
    #       #     - busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       #     - hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #       driver: virtio_net # Kernel driver, supports matching by wildcard.

    #       # # Bond specific options.
    #       # bond:
    #       #     # The interfaces that make up the bond.
    #       #     interfaces:
    #       #         - enp2s0
    #       #         - enp2s1
    #       #     # Picks a network device using the selector.
    #       #     deviceSelectors:
    #       #         - busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       #         - hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #           driver: virtio_net # Kernel driver, supports matching by wildcard.
    #       #     mode: 802.3ad # A bond option.
    #       #     lacpRate: fast # A bond option.

    #       # # Bridge specific options.
    #       # bridge:
    #       #     # The interfaces that make up the bridge.
    #       #     interfaces:
    #       #         - enxda4042ca9a51
    #       #         - enxae2a6774c259
    #       #     # Enable STP on this bridge.
    #       #     stp:
    #       #         enabled: true # Whether Spanning Tree Protocol (STP) is enabled.

    #       # # Configure this device as a bridge port.
    #       # bridgePort:
    #       #     master: br0 # The name of the bridge master interface

    #       # # Indicates if DHCP should be used to configure the interface.
    #       # dhcp: true

    #       # # DHCP specific options.
    #       # dhcpOptions:
    #       #     routeMetric: 1024 # The priority of all routes received via DHCP.

    #       # # Wireguard specific configuration.

    #       # # wireguard server example
    #       # wireguard:
    #       #     privateKey: ABCDEF... # Specifies a private key configuration (base64 encoded).
    #       #     listenPort: 51111 # Specifies a device's listening port.
    #       #     # Specifies a list of peer configurations to apply to a device.
    #       #     peers:
    #       #         - publicKey: ABCDEF... # Specifies the public key of this peer.
    #       #           endpoint: 192.168.1.3 # Specifies the endpoint of this peer entry.
    #       #           # AllowedIPs specifies a list of allowed IP addresses in CIDR notation for this peer.
    #       #           allowedIPs:
    #       #             - 192.168.1.0/24
    #       # # wireguard peer example
    #       # wireguard:
    #       #     privateKey: ABCDEF... # Specifies a private key configuration (base64 encoded).
    #       #     # Specifies a list of peer configurations to apply to a device.
    #       #     peers:
    #       #         - publicKey: ABCDEF... # Specifies the public key of this peer.
    #       #           endpoint: 192.168.1.2:51822 # Specifies the endpoint of this peer entry.
    #       #           persistentKeepaliveInterval: 10s # Specifies the persistent keepalive interval for this peer.
    #       #           # AllowedIPs specifies a list of allowed IP addresses in CIDR notation for this peer.
    #       #           allowedIPs:
    #       #             - 192.168.1.0/24

    #       # # Virtual (shared) IP address configuration.

    #       # # layer2 vip example
    #       # vip:
    #       #     ip: 172.16.199.55 # Specifies the IP address to be used.

    # # Used to statically set the nameservers for the machine.
    # nameservers:
    #     - 8.8.8.8
    #     - 1.1.1.1

    # # Used to statically set arbitrary search domains.
    # searchDomains:
    #     - example.org
    #     - example.com

    # # Allows for extra entries to be added to the `/etc/hosts` file
    # extraHostEntries:
    #     - ip: 192.168.1.100 # The IP of the host.
    #       # The host alias.
    #       aliases:
    #         - example
    #         - example.domain.tld

    # # Configures KubeSpan feature.
    # kubespan:
    #     enabled: true # Enable the KubeSpan feature.

    # Used to provide instructions for installations.
    install:
        disk: /dev/sda # The disk used for installations.
        image: ghcr.io/siderolabs/installer:v1.11.5 # Allows for supplying the image used to perform the installation.
        wipe: false # Indicates if the installation disk should be wiped at installation time.
        
        # # Look up disk using disk attributes like model, size, serial and others.
        # diskSelector:
        #     size: 4GB # Disk size.
        #     model: WDC* # Disk model `/sys/block/<dev>/device/model`.
        #     busPath: /pci0000:00/0000:00:17.0/ata1/host0/target0:0:0/0:0:0:0 # Disk bus path.

        # # Allows for supplying extra kernel args via the bootloader.
        # extraKernelArgs:
        #     - talos.platform=metal
        #     - reboot=k
    # Features describe individual Talos features that can be switched on or off.
    features:
        rbac: true # Enable role-based access control (RBAC).
        stableHostname: true # Enable stable default hostname.
        apidCheckExtKeyUsage: true # Enable checks for extended key usage of client certificates in apid.
        diskQuotaSupport: true # Enable XFS project quota support for EPHEMERAL partition and user disks.
        # KubePrism - local proxy/load balancer on defined port that will distribute
        kubePrism:
            enabled: true # Enable KubePrism support - will start local load balancing proxy.
            port: 7445 # KubePrism port.
        # Configures host DNS caching resolver.
        hostDNS:
            enabled: true # Enable host DNS caching resolver.
            forwardKubeDNSToHost: true # Use the host DNS resolver as upstream for Kubernetes CoreDNS pods.
        
        # # Configure Talos API access from Kubernetes pods.
        # kubernetesTalosAPIAccess:
        #     enabled: true # Enable Talos API access from Kubernetes pods.
        #     # The list of Talos API roles which can be granted for access from Kubernetes pods.
        #     allowedRoles:
        #         - os:reader
        #     # The list of Kubernetes namespaces Talos API access is available from.
        #     allowedKubernetesNamespaces:
        #         - kube-system
    # Configures the node labels for the machine.
    nodeLabels:
        node.kubernetes.io/exclude-from-external-load-balancers: ""
    
    # # Provides machine specific control plane configuration options.

    # # ControlPlane definition example.
    # controlPlane:
    #     # Controller manager machine specific configuration options.
    #     controllerManager:
    #         disabled: false # Disable kube-controller-manager on the node.
    #     # Scheduler machine specific configuration options.
    #     scheduler:
    #         disabled: true # Disable kube-scheduler on the node.

    # # Used to provide static pod definitions to be run by the kubelet directly bypassing the kube-apiserver.

    # # nginx static pod.
    # pods:
    #     - apiVersion: v1
    #       kind: pod
    #       metadata:
    #         name: nginx
    #       spec:
    #         containers:
    #             - image: nginx
    #               name: nginx

    # # Allows the addition of user specified files.

    # # MachineFiles usage example.
    # files:
    #     - content: '...' # The contents of the file.
    #       permissions: 0o666 # The file's permissions in octal.
    #       path: /tmp/file.txt # The path of the file.
    #       op: append # The operation to use

    # # The `env` field allows for the addition of environment variables.

    # # Environment variables definition examples.
    # env:
    #     GRPC_GO_LOG_SEVERITY_LEVEL: info
    #     GRPC_GO_LOG_VERBOSITY_LEVEL: "99"
    #     https_proxy: http://SERVER:PORT/
    # env:
    #     GRPC_GO_LOG_SEVERITY_LEVEL: error
    #     https_proxy: https://USERNAME:PASSWORD@SERVER:PORT/
    # env:
    #     https_proxy: http://DOMAIN\USERNAME:PASSWORD@SERVER:PORT/

    # # Used to configure the machine's time settings.

    # # Example configuration for cloudflare ntp server.
    # time:
    #     disabled: false # Indicates if the time service is disabled for the machine.
    #     # description: |
    #     servers:
    #         - time.cloudflare.com
    #     bootTimeout: 2m0s # Specifies the timeout when the node time is considered to be in sync unlocking the boot sequence.

    # # Used to configure the machine's sysctls.

    # # MachineSysctls usage example.
    # sysctls:
    #     kernel.domainname: talos.dev
    #     net.ipv4.ip_forward: "0"
    #     net/ipv6/conf/eth0.100/disable_ipv6: "1"

    # # Used to configure the machine's sysfs.

    # # MachineSysfs usage example.
    # sysfs:
    #     devices.system.cpu.cpu0.cpufreq.scaling_governor: performance

    # # Used to configure the machine's container image registry mirrors.
    # registries:
    #     # Specifies mirror configuration for each registry host namespace.
    #     mirrors:
    #         ghcr.io:
    #             # List of endpoints (URLs) for registry mirrors to use.
    #             endpoints:
    #                 - https://registry.insecure
    #                 - https://ghcr.io/v2/
    #     # Specifies TLS & auth configuration for HTTPS image registries.
    #     config:
    #         registry.insecure:
    #             # The TLS configuration for the registry.
    #             tls:
    #                 insecureSkipVerify: true # Skip TLS server certificate verification (not recommended).
    #                 
    #                 # # Enable mutual TLS authentication with the registry.
    #                 # clientIdentity:
    #                 #     crt: LS0tIEVYQU1QTEUgQ0VSVElGSUNBVEUgLS0t
    #                 #     key: LS0tIEVYQU1QTEUgS0VZIC0tLQ==
    #             
    #             # # The auth configuration for this registry.
    #             # auth:
    #             #     username: username # Optional registry authentication.
    #             #     password: password # Optional registry authentication.

    # # Configures the udev system.
    # udev:
    #     # List of udev rules to apply to the udev system
    #     rules:
    #         - SUBSYSTEM=="drm", KERNEL=="renderD*", GROUP="44", MODE="0660"

    # # Configures the logging system.
    # logging:
    #     # Logging destination.
    #     destinations:
    #         - endpoint: tcp://1.2.3.4:12345 # Where to send logs. Supported protocols are "tcp" and "udp".
    #           format: json_lines # Logs format.

    # # Configures the kernel.
    # kernel:
    #     # Kernel modules to load.
    #     modules:
    #         - name: brtfs # Module name.

    # # Configures the seccomp profiles for the machine.
    # seccompProfiles:
    #     - name: audit.json # The `name` field is used to provide the file name of the seccomp profile.
    #       # The `value` field is used to provide the seccomp profile.
    #       value:
    #         defaultAction: SCMP_ACT_LOG

    # # Override (patch) settings in the default OCI runtime spec for CRI containers.

    # # override default open file limit
    # baseRuntimeSpecOverrides:
    #     process:
    #         rlimits:
    #             - hard: 1024
    #               soft: 1024
    #               type: RLIMIT_NOFILE

    # # Configures the node annotations for the machine.

    # # node annotations example.
    # nodeAnnotations:
    #     customer.io/rack: r13a25

    # # Configures the node taints for the machine. Effect is optional.

    # Taint to prevent application workloads from scheduling on control plane
    nodeTaints:
        node-role.kubernetes.io/control-plane: "NoSchedule"
# Provides cluster specific configuration options.
cluster:
    id: WNkJLM_21eOqIhftJbTGfj3f9WKyoLHyqLtDLHFxhzI= # Globally unique identifier for this cluster (base64 encoded random 32 bytes).
    secret: MO9li78qAqIk2u0lLDTLokQPYvnG24DhmKaO/dE6CBE= # Shared secret of cluster (base64 encoded random 32 bytes).
    # Provides control plane specific configuration options.
    controlPlane:
        endpoint: https://46.62.218.181:6443 # Endpoint is the canonical controlplane endpoint, which can be an IP address or a DNS hostname.
    clusterName: bizmatters-dev-01 # Configures the cluster's name.
    # Provides cluster specific network configuration options.
    network:
        dnsDomain: cluster.local # The domain used by Kubernetes DNS.
        # The pod subnet CIDR.
        podSubnets:
            - 10.244.0.0/16
        # The service subnet CIDR.
        serviceSubnets:
            - 10.96.0.0/12
        
        # # The CNI used.
        # cni:
        #     name: custom # Name of CNI to use.
        #     # URLs containing manifests to apply for the CNI.
        #     urls:
        #         - https://docs.projectcalico.org/archive/v3.20/manifests/canal.yaml
    token: fof0k2.6coj67xh6sw4kksb # The [bootstrap token](https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/) used to join the cluster.
    secretboxEncryptionSecret: Lj+7Y/P3mf0eMhnwYfi3vNfyJEKhMvqlUH7F2fK1J7Y= # A key used for the [encryption of secret data at rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).
    # The base64 encoded root certificate authority used by Kubernetes.
    ca:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJpVENDQVMrZ0F3SUJBZ0lRWDcybVpTOUZ6ZzE5M3lOK0pwTkdZREFLQmdncWhrak9QUVFEQWpBVk1STXcKRVFZRFZRUUtFd3ByZFdKbGNtNWxkR1Z6TUI0WERUSTFNVEV5TkRBNU1EazFNMW9YRFRNMU1URXlNakE1TURrMQpNMW93RlRFVE1CRUdBMVVFQ2hNS2EzVmlaWEp1WlhSbGN6QlpNQk1HQnlxR1NNNDlBZ0VHQ0NxR1NNNDlBd0VICkEwSUFCQ0l5MHNidlJ2SzlwakR5bE5URjRranFkRVRmbExPNFhIVUdDeW13VlY5VFI0ODZzN1BFYmJveThkSWkKKy9NWDZSRHdGQ3NxWElKVHFJd3BCczNBakJDallUQmZNQTRHQTFVZER3RUIvd1FFQXdJQ2hEQWRCZ05WSFNVRQpGakFVQmdnckJnRUZCUWNEQVFZSUt3WUJCUVVIQXdJd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFCkZnUVVjZ0pseEcvWkYvay8rMVEwN1VMdGVta0NoSHN3Q2dZSUtvWkl6ajBFQXdJRFNBQXdSUUlnRkQxQXEwZEoKcU5kTENkRFF6cERPcjJKTFR5dGRBM1ozcUE5SEVjNU1zaTRDSVFEaTFzaFI4YVNlR1c4ZmlrZlZCY3JCa1o4dQp4MkdjZHd3K3FYVnFnWlpJRWc9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUhYd0FOVWtqd0tZbkg0bmN4amxrVFJidGhWQXM2Q1JYMWlzc2xuQ0ZEelRvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFSWpMU3h1OUc4cjJtTVBLVTFNWGlTT3AwUk4rVXM3aGNkUVlMS2JCVlgxTkhqenF6czhSdAp1akx4MGlMNzh4ZnBFUEFVS3lwY2dsT29qQ2tHemNDTUVBPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    # The base64 encoded aggregator certificate authority used by Kubernetes for front-proxy certificate generation.
    aggregatorCA:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJZRENDQVFhZ0F3SUJBZ0lSQU5hVit5Wjk5b2cxN213VUR3Sk1RZGt3Q2dZSUtvWkl6ajBFQXdJd0FEQWUKRncweU5URXhNalF3T1RBNU5UTmFGdzB6TlRFeE1qSXdPVEE1TlROYU1BQXdXVEFUQmdjcWhrak9QUUlCQmdncQpoa2pPUFFNQkJ3TkNBQVR6N2cyeHRUZXRRS2tqUlBGLzBZdEVyNDMzdGN2ZGwvQ2FQYnJXQkRYVG14Z0dYeW5xClJ6THUvZCtlaVNLZzk0Y2ZsVEhEZFQxUHJqckREb0gvVmxObW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXcKSFFZRFZSMGxCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4dwpIUVlEVlIwT0JCWUVGSHlWZ1FHdE9SMWdVVzl2RXpqNkE5eUQybFBRTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDCklCWEdNM2pJSVl1ZHN2MFRlU01WTjh2MFFGT2Faa0Z0REFhc3FYaHhOeE1lQWlFQWgydG5DdXFObnBoWmNmQXkKT1FsWThyYVh6UE1TMTRNekg3YVNTbzYrK3owPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUxPR3hOMDNtMTJsVXNtYTRmdkpaaFlYZFlYd0JkaFgyam9tVm1icmFrd0lvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFOCs0TnNiVTNyVUNwSTBUeGY5R0xSSytOOTdYTDNaZndtajI2MWdRMTA1c1lCbDhwNmtjeQo3djNmbm9raW9QZUhINVV4dzNVOVQ2NDZ3dzZCLzFaVFpnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    # The base64 encoded private key for service account token generation.
    serviceAccount:
        key: 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
    # API server specific configuration options.
    apiServer:
        image: registry.k8s.io/kube-apiserver:v1.34.1 # The container image used in the API server manifest.
        # Extra certificate subject alternative names for the API server's certificate.
        certSANs:
            - 46.62.218.181
        disablePodSecurityPolicy: true # Disable PodSecurityPolicy in the API server and default manifests.
        # Configure the API server admission plugins.
        admissionControl:
            - name: PodSecurity # Name is the name of the admission controller.
              # Configuration is an embedded configuration object to be used as the plugin's
              configuration:
                apiVersion: pod-security.admission.config.k8s.io/v1alpha1
                defaults:
                    audit: restricted
                    audit-version: latest
                    enforce: baseline
                    enforce-version: latest
                    warn: restricted
                    warn-version: latest
                exemptions:
                    namespaces:
                        - kube-system
                        - local-path-storage
                        - intelligence
                    runtimeClasses: []
                    usernames: []
                kind: PodSecurityConfiguration
        # Configure the API server audit policy.
        auditPolicy:
            apiVersion: audit.k8s.io/v1
            kind: Policy
            rules:
                - level: Metadata
        
        # # Configure the API server authorization config. Node and RBAC authorizers are always added irrespective of the configuration.
        # authorizationConfig:
        #     - type: Webhook # Type is the name of the authorizer. Allowed values are `Node`, `RBAC`, and `Webhook`.
        #       name: webhook # Name is used to describe the authorizer.
        #       # webhook is the configuration for the webhook authorizer.
        #       webhook:
        #         connectionInfo:
        #             type: InClusterConfig
        #         failurePolicy: Deny
        #         matchConditionSubjectAccessReviewVersion: v1
        #         matchConditions:
        #             - expression: has(request.resourceAttributes)
        #             - expression: '!(\''system:serviceaccounts:kube-system\'' in request.groups)'
        #         subjectAccessReviewVersion: v1
        #         timeout: 3s
        #     - type: Webhook # Type is the name of the authorizer. Allowed values are `Node`, `RBAC`, and `Webhook`.
        #       name: in-cluster-authorizer # Name is used to describe the authorizer.
        #       # webhook is the configuration for the webhook authorizer.
        #       webhook:
        #         connectionInfo:
        #             type: InClusterConfig
        #         failurePolicy: NoOpinion
        #         matchConditionSubjectAccessReviewVersion: v1
        #         subjectAccessReviewVersion: v1
        #         timeout: 3s
    # Controller manager server specific configuration options.
    controllerManager:
        image: registry.k8s.io/kube-controller-manager:v1.34.1 # The container image used in the controller manager manifest.
    # Kube-proxy server-specific configuration options
    proxy:
        image: registry.k8s.io/kube-proxy:v1.34.1 # The container image used in the kube-proxy manifest.
        
        # # Disable kube-proxy deployment on cluster bootstrap.
        # disabled: false
    # Scheduler server specific configuration options.
    scheduler:
        image: registry.k8s.io/kube-scheduler:v1.34.1 # The container image used in the scheduler manifest.
    # Configures cluster member discovery.
    discovery:
        enabled: true # Enable the cluster membership discovery feature.
        # Configure registries used for cluster member discovery.
        registries:
            # Kubernetes registry uses Kubernetes API server to discover cluster members and stores additional information
            kubernetes:
                disabled: true # Disable Kubernetes discovery registry.
            # Service registry is using an external service to push and pull information about cluster members.
            service: {}
            # # External service endpoint.
            # endpoint: https://discovery.talos.dev/
    # Etcd specific configuration options.
    etcd:
        # The `ca` is the root certificate authority of the PKI.
        ca:
            crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJmekNDQVNTZ0F3SUJBZ0lSQU1od24yZ0xYQXhOalBXdHRXdGhBNTR3Q2dZSUtvWkl6ajBFQXdJd0R6RU4KTUFzR0ExVUVDaE1FWlhSalpEQWVGdzB5TlRFeE1qUXdPVEE1TlROYUZ3MHpOVEV4TWpJd09UQTVOVE5hTUE4eApEVEFMQmdOVkJBb1RCR1YwWTJRd1dUQVRCZ2NxaGtqT1BRSUJCZ2dxaGtqT1BRTUJCd05DQUFUZmJ6WEhka25LCkYrQWV3NzhNTFNGSXBtc1pSbkFNcUJoUytneW1LVStyelVRQ21vMlovNk91L1NXdEJqYUEwdkVXQ0kzcUl1RGMKZ0NUeFY5cXNjMXdjbzJFd1h6QU9CZ05WSFE4QkFmOEVCQU1DQW9Rd0hRWURWUjBsQkJZd0ZBWUlLd1lCQlFVSApBd0VHQ0NzR0FRVUZCd01DTUE4R0ExVWRFd0VCL3dRRk1BTUJBZjh3SFFZRFZSME9CQllFRklZc1lFeHpVMVEzCkpDelZLRlVKdStERjBEYmhNQW9HQ0NxR1NNNDlCQU1DQTBrQU1FWUNJUURTWUE4NWgzcE9WK0NWanI4cGp5bmkKbTdYTEkxZEQ5eFhuaDZTQkFLSnpFQUloQU0ySlJLT3FWRmJGaGZWMkgxM2lZbVU5NmtqU0NyNStGakhVZlFFcgpza3B0Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
            key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUltc3l1YU1NRWZLbTl6Y0gvQS81dk9NVXo4cHZhczRBMHpmMHZyYVAzaldvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFMzI4MXgzWkp5aGZnSHNPL0RDMGhTS1pyR1Vad0RLZ1lVdm9NcGlsUHE4MUVBcHFObWYragpydjBsclFZMmdOTHhGZ2lONmlMZzNJQWs4VmZhckhOY0hBPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
        
        # # The container image used to create the etcd service.
        # image: gcr.io/etcd-development/etcd:v3.6.5

        # # The `advertisedSubnets` field configures the networks to pick etcd advertised IP from.
        # advertisedSubnets:
        #     - 10.0.0.0/8
    allowSchedulingOnControlPlanes: true # Allows running workload on control-plane nodes.
    # Cilium CNI for bootstrap - minimal config
    # ArgoCD will adopt and enable full features (Hubble, Gateway API)
    inlineManifests:
        - name: cilium-bootstrap
          contents: |
            ---
            # Source: cilium/templates/cilium-agent/serviceaccount.yaml
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: "cilium"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-envoy/serviceaccount.yaml
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: "cilium-envoy"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-operator/serviceaccount.yaml
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: "cilium-operator"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-configmap.yaml
            apiVersion: v1
            kind: ConfigMap
            metadata:
              name: cilium-config
              namespace: kube-system
            data:
            
              # Identity allocation mode selects how identities are shared between cilium
              # nodes by setting how they are stored. The options are "crd" or "kvstore".
              # - "crd" stores identities in kubernetes as CRDs (custom resource definition).
              #   These can be queried with:
              #     kubectl get ciliumid
              # - "kvstore" stores identities in an etcd kvstore, that is
              #   configured below. Cilium versions before 1.6 supported only the kvstore
              #   backend. Upgrades from these older cilium versions should continue using
              #   the kvstore by commenting out the identity-allocation-mode below, or
              #   setting it to "kvstore".
              identity-allocation-mode: crd
              identity-heartbeat-timeout: "30m0s"
              identity-gc-interval: "15m0s"
              cilium-endpoint-gc-interval: "5m0s"
              nodes-gc-interval: "5m0s"
            
              # If you want to run cilium in debug mode change this value to true
              debug: "false"
              debug-verbose: ""
              # The agent can be put into the following three policy enforcement modes
              # default, always and never.
              # https://docs.cilium.io/en/latest/security/policy/intro/#policy-enforcement-modes
              enable-policy: "default"
              policy-cidr-match-mode: ""
              # If you want metrics enabled in cilium-operator, set the port for
              # which the Cilium Operator will have their metrics exposed.
              # NOTE that this will open the port on the nodes where Cilium operator pod
              # is scheduled.
              operator-prometheus-serve-addr: ":9963"
              enable-metrics: "true"
            
              # Enable IPv4 addressing. If enabled, all endpoints are allocated an IPv4
              # address.
              enable-ipv4: "true"
            
              # Enable IPv6 addressing. If enabled, all endpoints are allocated an IPv6
              # address.
              enable-ipv6: "false"
              # Users who wish to specify their own custom CNI configuration file must set
              # custom-cni-conf to "true", otherwise Cilium may overwrite the configuration.
              custom-cni-conf: "false"
              enable-bpf-clock-probe: "false"
              # If you want cilium monitor to aggregate tracing for packets, set this level
              # to "low", "medium", or "maximum". The higher the level, the less packets
              # that will be seen in monitor output.
              monitor-aggregation: medium
            
              # The monitor aggregation interval governs the typical time between monitor
              # notification events for each allowed connection.
              #
              # Only effective when monitor aggregation is set to "medium" or higher.
              monitor-aggregation-interval: "5s"
            
              # The monitor aggregation flags determine which TCP flags which, upon the
              # first observation, cause monitor notifications to be generated.
              #
              # Only effective when monitor aggregation is set to "medium" or higher.
              monitor-aggregation-flags: all
              # Specifies the ratio (0.0-1.0] of total system memory to use for dynamic
              # sizing of the TCP CT, non-TCP CT, NAT and policy BPF maps.
              bpf-map-dynamic-size-ratio: "0.0025"
              # bpf-policy-map-max specifies the maximum number of entries in endpoint
              # policy map (per endpoint)
              bpf-policy-map-max: "16384"
              # bpf-lb-map-max specifies the maximum number of entries in bpf lb service,
              # backend and affinity maps.
              bpf-lb-map-max: "65536"
              bpf-lb-external-clusterip: "false"
            
              bpf-events-drop-enabled: "true"
              bpf-events-policy-verdict-enabled: "true"
              bpf-events-trace-enabled: "true"
            
              # Pre-allocation of map entries allows per-packet latency to be reduced, at
              # the expense of up-front memory allocation for the entries in the maps. The
              # default value below will minimize memory usage in the default installation;
              # users who are sensitive to latency may consider setting this to "true".
              #
              # This option was introduced in Cilium 1.4. Cilium 1.3 and earlier ignore
              # this option and behave as though it is set to "true".
              #
              # If this value is modified, then during the next Cilium startup the restore
              # of existing endpoints and tracking of ongoing connections may be disrupted.
              # As a result, reply packets may be dropped and the load-balancing decisions
              # for established connections may change.
              #
              # If this option is set to "false" during an upgrade from 1.3 or earlier to
              # 1.4 or later, then it may cause one-time disruptions during the upgrade.
              preallocate-bpf-maps: "false"
            
              # Name of the cluster. Only relevant when building a mesh of clusters.
              cluster-name: default
              # Unique ID of the cluster. Must be unique across all conneted clusters and
              # in the range of 1 and 255. Only relevant when building a mesh of clusters.
              cluster-id: "0"
            
              # Encapsulation mode for communication between nodes
              # Possible values:
              #   - disabled
              #   - vxlan (default)
              #   - geneve
              # Default case
              routing-mode: "tunnel"
              tunnel-protocol: "vxlan"
              service-no-backend-response: "reject"
            
            
              # Enables L7 proxy for L7 policy enforcement and visibility
              enable-l7-proxy: "true"
            
              enable-ipv4-masquerade: "true"
              enable-ipv4-big-tcp: "false"
              enable-ipv6-big-tcp: "false"
              enable-ipv6-masquerade: "true"
              enable-tcx: "true"
              datapath-mode: "veth"
              enable-masquerade-to-route-source: "false"
            
              enable-xt-socket-fallback: "true"
              install-no-conntrack-iptables-rules: "false"
            
              auto-direct-node-routes: "false"
              direct-routing-skip-unreachable: "false"
              enable-local-redirect-policy: "false"
              enable-runtime-device-detection: "true"
            
              kube-proxy-replacement: "true"
              kube-proxy-replacement-healthz-bind-address: ""
              bpf-lb-sock: "false"
              bpf-lb-sock-terminate-pod-connections: "false"
              nodeport-addresses: ""
              enable-health-check-nodeport: "true"
              enable-health-check-loadbalancer-ip: "false"
              node-port-bind-protection: "true"
              enable-auto-protect-node-port-range: "true"
              bpf-lb-acceleration: "disabled"
              enable-svc-source-range-check: "true"
              enable-l2-neigh-discovery: "true"
              arping-refresh-period: "30s"
              k8s-require-ipv4-pod-cidr: "false"
              k8s-require-ipv6-pod-cidr: "false"
              enable-k8s-networkpolicy: "true"
              # Tell the agent to generate and write a CNI configuration file
              write-cni-conf-when-ready: /host/etc/cni/net.d/05-cilium.conflist
              cni-exclusive: "true"
              cni-log-file: "/var/run/cilium/cilium-cni.log"
              enable-endpoint-health-checking: "true"
              enable-health-checking: "true"
              enable-well-known-identities: "false"
              enable-node-selector-labels: "false"
              synchronize-k8s-nodes: "true"
              operator-api-serve-addr: "127.0.0.1:9234"
              ipam: "kubernetes"
              ipam-cilium-node-update-rate: "15s"
              egress-gateway-reconciliation-trigger-interval: "1s"
              enable-vtep: "false"
              vtep-endpoint: ""
              vtep-cidr: ""
              vtep-mask: ""
              vtep-mac: ""
              procfs: "/host/proc"
              bpf-root: "/sys/fs/bpf"
              cgroup-root: "/sys/fs/cgroup"
              enable-k8s-terminating-endpoint: "true"
              enable-sctp: "false"
            
              k8s-client-qps: "10"
              k8s-client-burst: "20"
              remove-cilium-node-taints: "true"
              set-cilium-node-taints: "true"
              set-cilium-is-up-condition: "true"
              unmanaged-pod-watcher-interval: "15"
              # default DNS proxy to transparent mode in non-chaining modes
              dnsproxy-enable-transparent-mode: "true"
              dnsproxy-socket-linger-timeout: "10"
              tofqdns-dns-reject-response-code: "refused"
              tofqdns-enable-dns-compression: "true"
              tofqdns-endpoint-max-ip-per-hostname: "50"
              tofqdns-idle-connection-grace-period: "0s"
              tofqdns-max-deferred-connection-deletes: "10000"
              tofqdns-proxy-response-max-delay: "100ms"
              agent-not-ready-taint-key: "node.cilium.io/agent-not-ready"
            
              mesh-auth-enabled: "true"
              mesh-auth-queue-size: "1024"
              mesh-auth-rotated-identities-queue-size: "1024"
              mesh-auth-gc-interval: "5m0s"
            
              proxy-xff-num-trusted-hops-ingress: "0"
              proxy-xff-num-trusted-hops-egress: "0"
              proxy-connect-timeout: "2"
              proxy-max-requests-per-connection: "0"
              proxy-max-connection-duration-seconds: "0"
              proxy-idle-timeout-seconds: "60"
            
              external-envoy-proxy: "true"
              envoy-base-id: "0"
            
              envoy-keep-cap-netbindservice: "false"
              max-connected-clusters: "255"
              clustermesh-enable-endpoint-sync: "false"
              clustermesh-enable-mcs-api: "false"
            
              nat-map-stats-entries: "32"
              nat-map-stats-interval: "30s"
            
            # Extra config allows adding arbitrary properties to the cilium config.
            # By putting it at the end of the ConfigMap, it's also possible to override existing properties.
            ---
            # Source: cilium/templates/cilium-envoy/configmap.yaml
            apiVersion: v1
            kind: ConfigMap
            metadata:
              name: cilium-envoy-config
              namespace: kube-system
            data:
              bootstrap-config.json: |
                {
                  "node": {
                    "id": "host~127.0.0.1~no-id~localdomain",
                    "cluster": "ingress-cluster"
                  },
                  "staticResources": {
                    "listeners": [
                      {
                        "name": "envoy-prometheus-metrics-listener",
                        "address": {
                          "socket_address": {
                            "address": "0.0.0.0",
                            "port_value": 9964
                          }
                        },
                        "filter_chains": [
                          {
                            "filters": [
                              {
                                "name": "envoy.filters.network.http_connection_manager",
                                "typed_config": {
                                  "@type": "type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager",
                                  "stat_prefix": "envoy-prometheus-metrics-listener",
                                  "route_config": {
                                    "virtual_hosts": [
                                      {
                                        "name": "prometheus_metrics_route",
                                        "domains": [
                                          "*"
                                        ],
                                        "routes": [
                                          {
                                            "name": "prometheus_metrics_route",
                                            "match": {
                                              "prefix": "/metrics"
                                            },
                                            "route": {
                                              "cluster": "/envoy-admin",
                                              "prefix_rewrite": "/stats/prometheus"
                                            }
                                          }
                                        ]
                                      }
                                    ]
                                  },
                                  "http_filters": [
                                    {
                                      "name": "envoy.filters.http.router",
                                      "typed_config": {
                                        "@type": "type.googleapis.com/envoy.extensions.filters.http.router.v3.Router"
                                      }
                                    }
                                  ],
                                  "stream_idle_timeout": "0s"
                                }
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "name": "envoy-health-listener",
                        "address": {
                          "socket_address": {
                            "address": "127.0.0.1",
                            "port_value": 9878
                          }
                        },
                        "filter_chains": [
                          {
                            "filters": [
                              {
                                "name": "envoy.filters.network.http_connection_manager",
                                "typed_config": {
                                  "@type": "type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager",
                                  "stat_prefix": "envoy-health-listener",
                                  "route_config": {
                                    "virtual_hosts": [
                                      {
                                        "name": "health",
                                        "domains": [
                                          "*"
                                        ],
                                        "routes": [
                                          {
                                            "name": "health",
                                            "match": {
                                              "prefix": "/healthz"
                                            },
                                            "route": {
                                              "cluster": "/envoy-admin",
                                              "prefix_rewrite": "/ready"
                                            }
                                          }
                                        ]
                                      }
                                    ]
                                  },
                                  "http_filters": [
                                    {
                                      "name": "envoy.filters.http.router",
                                      "typed_config": {
                                        "@type": "type.googleapis.com/envoy.extensions.filters.http.router.v3.Router"
                                      }
                                    }
                                  ],
                                  "stream_idle_timeout": "0s"
                                }
                              }
                            ]
                          }
                        ]
                      }
                    ],
                    "clusters": [
                      {
                        "name": "ingress-cluster",
                        "type": "ORIGINAL_DST",
                        "connectTimeout": "2s",
                        "lbPolicy": "CLUSTER_PROVIDED",
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "commonHttpProtocolOptions": {
                              "idleTimeout": "60s",
                              "maxConnectionDuration": "0s",
                              "maxRequestsPerConnection": 0
                            },
                            "useDownstreamProtocolConfig": {}
                          }
                        },
                        "cleanupInterval": "2.500s"
                      },
                      {
                        "name": "egress-cluster-tls",
                        "type": "ORIGINAL_DST",
                        "connectTimeout": "2s",
                        "lbPolicy": "CLUSTER_PROVIDED",
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "commonHttpProtocolOptions": {
                              "idleTimeout": "60s",
                              "maxConnectionDuration": "0s",
                              "maxRequestsPerConnection": 0
                            },
                            "upstreamHttpProtocolOptions": {},
                            "useDownstreamProtocolConfig": {}
                          }
                        },
                        "cleanupInterval": "2.500s",
                        "transportSocket": {
                          "name": "cilium.tls_wrapper",
                          "typedConfig": {
                            "@type": "type.googleapis.com/cilium.UpstreamTlsWrapperContext"
                          }
                        }
                      },
                      {
                        "name": "egress-cluster",
                        "type": "ORIGINAL_DST",
                        "connectTimeout": "2s",
                        "lbPolicy": "CLUSTER_PROVIDED",
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "commonHttpProtocolOptions": {
                              "idleTimeout": "60s",
                              "maxConnectionDuration": "0s",
                              "maxRequestsPerConnection": 0
                            },
                            "useDownstreamProtocolConfig": {}
                          }
                        },
                        "cleanupInterval": "2.500s"
                      },
                      {
                        "name": "ingress-cluster-tls",
                        "type": "ORIGINAL_DST",
                        "connectTimeout": "2s",
                        "lbPolicy": "CLUSTER_PROVIDED",
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "commonHttpProtocolOptions": {
                              "idleTimeout": "60s",
                              "maxConnectionDuration": "0s",
                              "maxRequestsPerConnection": 0
                            },
                            "upstreamHttpProtocolOptions": {},
                            "useDownstreamProtocolConfig": {}
                          }
                        },
                        "cleanupInterval": "2.500s",
                        "transportSocket": {
                          "name": "cilium.tls_wrapper",
                          "typedConfig": {
                            "@type": "type.googleapis.com/cilium.UpstreamTlsWrapperContext"
                          }
                        }
                      },
                      {
                        "name": "xds-grpc-cilium",
                        "type": "STATIC",
                        "connectTimeout": "2s",
                        "loadAssignment": {
                          "clusterName": "xds-grpc-cilium",
                          "endpoints": [
                            {
                              "lbEndpoints": [
                                {
                                  "endpoint": {
                                    "address": {
                                      "pipe": {
                                        "path": "/var/run/cilium/envoy/sockets/xds.sock"
                                      }
                                    }
                                  }
                                }
                              ]
                            }
                          ]
                        },
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "explicitHttpConfig": {
                              "http2ProtocolOptions": {}
                            }
                          }
                        }
                      },
                      {
                        "name": "/envoy-admin",
                        "type": "STATIC",
                        "connectTimeout": "2s",
                        "loadAssignment": {
                          "clusterName": "/envoy-admin",
                          "endpoints": [
                            {
                              "lbEndpoints": [
                                {
                                  "endpoint": {
                                    "address": {
                                      "pipe": {
                                        "path": "/var/run/cilium/envoy/sockets/admin.sock"
                                      }
                                    }
                                  }
                                }
                              ]
                            }
                          ]
                        }
                      }
                    ]
                  },
                  "dynamicResources": {
                    "ldsConfig": {
                      "apiConfigSource": {
                        "apiType": "GRPC",
                        "transportApiVersion": "V3",
                        "grpcServices": [
                          {
                            "envoyGrpc": {
                              "clusterName": "xds-grpc-cilium"
                            }
                          }
                        ],
                        "setNodeOnFirstMessageOnly": true
                      },
                      "resourceApiVersion": "V3"
                    },
                    "cdsConfig": {
                      "apiConfigSource": {
                        "apiType": "GRPC",
                        "transportApiVersion": "V3",
                        "grpcServices": [
                          {
                            "envoyGrpc": {
                              "clusterName": "xds-grpc-cilium"
                            }
                          }
                        ],
                        "setNodeOnFirstMessageOnly": true
                      },
                      "resourceApiVersion": "V3"
                    }
                  },
                  "bootstrapExtensions": [
                    {
                      "name": "envoy.bootstrap.internal_listener",
                      "typed_config": {
                        "@type": "type.googleapis.com/envoy.extensions.bootstrap.internal_listener.v3.InternalListener"
                      }
                    }
                  ],
                  "layeredRuntime": {
                    "layers": [
                      {
                        "name": "static_layer_0",
                        "staticLayer": {
                          "overload": {
                            "global_downstream_max_connections": 50000
                          }
                        }
                      }
                    ]
                  },
                  "admin": {
                    "address": {
                      "pipe": {
                        "path": "/var/run/cilium/envoy/sockets/admin.sock"
                      }
                    }
                  }
                }
            ---
            # Source: cilium/templates/cilium-agent/clusterrole.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: cilium
              labels:
                app.kubernetes.io/part-of: cilium
            rules:
            - apiGroups:
              - networking.k8s.io
              resources:
              - networkpolicies
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - discovery.k8s.io
              resources:
              - endpointslices
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - ""
              resources:
              - namespaces
              - services
              - pods
              - endpoints
              - nodes
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - apiextensions.k8s.io
              resources:
              - customresourcedefinitions
              verbs:
              - list
              - watch
              # This is used when validating policies in preflight. This will need to stay
              # until we figure out how to avoid "get" inside the preflight, and then
              # should be removed ideally.
              - get
            - apiGroups:
              - cilium.io
              resources:
              - ciliumloadbalancerippools
              - ciliumbgppeeringpolicies
              - ciliumbgpnodeconfigs
              - ciliumbgpadvertisements
              - ciliumbgppeerconfigs
              - ciliumclusterwideenvoyconfigs
              - ciliumclusterwidenetworkpolicies
              - ciliumegressgatewaypolicies
              - ciliumendpoints
              - ciliumendpointslices
              - ciliumenvoyconfigs
              - ciliumidentities
              - ciliumlocalredirectpolicies
              - ciliumnetworkpolicies
              - ciliumnodes
              - ciliumnodeconfigs
              - ciliumcidrgroups
              - ciliuml2announcementpolicies
              - ciliumpodippools
              verbs:
              - list
              - watch
            - apiGroups:
              - cilium.io
              resources:
              - ciliumidentities
              - ciliumendpoints
              - ciliumnodes
              verbs:
              - create
            - apiGroups:
              - cilium.io
              # To synchronize garbage collection of such resources
              resources:
              - ciliumidentities
              verbs:
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumendpoints
              verbs:
              - delete
              - get
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnodes
              - ciliumnodes/status
              verbs:
              - get
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumendpoints/status
              - ciliumendpoints
              - ciliuml2announcementpolicies/status
              - ciliumbgpnodeconfigs/status
              verbs:
              - patch
            ---
            # Source: cilium/templates/cilium-operator/clusterrole.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: cilium-operator
              labels:
                app.kubernetes.io/part-of: cilium
            rules:
            - apiGroups:
              - ""
              resources:
              - pods
              verbs:
              - get
              - list
              - watch
              # to automatically delete [core|kube]dns pods so that are starting to being
              # managed by Cilium
              - delete
            - apiGroups:
              - ""
              resources:
              - nodes
              verbs:
              - list
              - watch
            - apiGroups:
              - ""
              resources:
              # To remove node taints
              - nodes
              # To set NetworkUnavailable false on startup
              - nodes/status
              verbs:
              - patch
            - apiGroups:
              - discovery.k8s.io
              resources:
              - endpointslices
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - ""
              resources:
              # to perform LB IP allocation for BGP
              - services/status
              verbs:
              - update
              - patch
            - apiGroups:
              - ""
              resources:
              # to check apiserver connectivity
              - namespaces
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - ""
              resources:
              # to perform the translation of a CNP that contains `ToGroup` to its endpoints
              - services
              - endpoints
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnetworkpolicies
              - ciliumclusterwidenetworkpolicies
              verbs:
              # Create auto-generated CNPs and CCNPs from Policies that have 'toGroups'
              - create
              - update
              - deletecollection
              # To update the status of the CNPs and CCNPs
              - patch
              - get
              - list
              - watch
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnetworkpolicies/status
              - ciliumclusterwidenetworkpolicies/status
              verbs:
              # Update the auto-generated CNPs and CCNPs status.
              - patch
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumendpoints
              - ciliumidentities
              verbs:
              # To perform garbage collection of such resources
              - delete
              - list
              - watch
            - apiGroups:
              - cilium.io
              resources:
              - ciliumidentities
              verbs:
              # To synchronize garbage collection of such resources
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnodes
              verbs:
              - create
              - update
              - get
              - list
              - watch
                # To perform CiliumNode garbage collector
              - delete
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnodes/status
              verbs:
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumendpointslices
              - ciliumenvoyconfigs
              - ciliumbgppeerconfigs
              - ciliumbgpadvertisements
              - ciliumbgpnodeconfigs
              verbs:
              - create
              - update
              - get
              - list
              - watch
              - delete
              - patch
            - apiGroups:
              - apiextensions.k8s.io
              resources:
              - customresourcedefinitions
              verbs:
              - create
              - get
              - list
              - watch
            - apiGroups:
              - apiextensions.k8s.io
              resources:
              - customresourcedefinitions
              verbs:
              - update
              resourceNames:
              - ciliumloadbalancerippools.cilium.io
              - ciliumbgppeeringpolicies.cilium.io
              - ciliumbgpclusterconfigs.cilium.io
              - ciliumbgppeerconfigs.cilium.io
              - ciliumbgpadvertisements.cilium.io
              - ciliumbgpnodeconfigs.cilium.io
              - ciliumbgpnodeconfigoverrides.cilium.io
              - ciliumclusterwideenvoyconfigs.cilium.io
              - ciliumclusterwidenetworkpolicies.cilium.io
              - ciliumegressgatewaypolicies.cilium.io
              - ciliumendpoints.cilium.io
              - ciliumendpointslices.cilium.io
              - ciliumenvoyconfigs.cilium.io
              - ciliumexternalworkloads.cilium.io
              - ciliumidentities.cilium.io
              - ciliumlocalredirectpolicies.cilium.io
              - ciliumnetworkpolicies.cilium.io
              - ciliumnodes.cilium.io
              - ciliumnodeconfigs.cilium.io
              - ciliumcidrgroups.cilium.io
              - ciliuml2announcementpolicies.cilium.io
              - ciliumpodippools.cilium.io
            - apiGroups:
              - cilium.io
              resources:
              - ciliumloadbalancerippools
              - ciliumpodippools
              - ciliumbgppeeringpolicies
              - ciliumbgpclusterconfigs
              - ciliumbgpnodeconfigoverrides
              verbs:
              - get
              - list
              - watch
            - apiGroups:
                - cilium.io
              resources:
                - ciliumpodippools
              verbs:
                - create
            - apiGroups:
              - cilium.io
              resources:
              - ciliumloadbalancerippools/status
              verbs:
              - patch
            # For cilium-operator running in HA mode.
            #
            # Cilium operator running in HA mode requires the use of ResourceLock for Leader Election
            # between multiple running instances.
            # The preferred way of doing this is to use LeasesResourceLock as edits to Leases are less
            # common and fewer objects in the cluster watch "all Leases".
            - apiGroups:
              - coordination.k8s.io
              resources:
              - leases
              verbs:
              - create
              - get
              - update
            ---
            # Source: cilium/templates/cilium-agent/clusterrolebinding.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              name: cilium
              labels:
                app.kubernetes.io/part-of: cilium
            roleRef:
              apiGroup: rbac.authorization.k8s.io
              kind: ClusterRole
              name: cilium
            subjects:
            - kind: ServiceAccount
              name: "cilium"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-operator/clusterrolebinding.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              name: cilium-operator
              labels:
                app.kubernetes.io/part-of: cilium
            roleRef:
              apiGroup: rbac.authorization.k8s.io
              kind: ClusterRole
              name: cilium-operator
            subjects:
            - kind: ServiceAccount
              name: "cilium-operator"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-agent/role.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: cilium-config-agent
              namespace: kube-system
              labels:
                app.kubernetes.io/part-of: cilium
            rules:
            - apiGroups:
              - ""
              resources:
              - configmaps
              verbs:
              - get
              - list
              - watch
            ---
            # Source: cilium/templates/cilium-agent/rolebinding.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: cilium-config-agent
              namespace: kube-system
              labels:
                app.kubernetes.io/part-of: cilium
            roleRef:
              apiGroup: rbac.authorization.k8s.io
              kind: Role
              name: cilium-config-agent
            subjects:
              - kind: ServiceAccount
                name: "cilium"
                namespace: kube-system
            ---
            # Source: cilium/templates/cilium-agent/daemonset.yaml
            apiVersion: apps/v1
            kind: DaemonSet
            metadata:
              name: cilium
              namespace: kube-system
              labels:
                k8s-app: cilium
                app.kubernetes.io/part-of: cilium
                app.kubernetes.io/name: cilium-agent
            spec:
              selector:
                matchLabels:
                  k8s-app: cilium
              updateStrategy:
                rollingUpdate:
                  maxUnavailable: 2
                type: RollingUpdate
              template:
                metadata:
                  annotations:
                  labels:
                    k8s-app: cilium
                    app.kubernetes.io/name: cilium-agent
                    app.kubernetes.io/part-of: cilium
                spec:
                  securityContext:
                    appArmorProfile:
                      type: Unconfined
                  containers:
                  - name: cilium-agent
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    command:
                    - cilium-agent
                    args:
                    - --config-dir=/tmp/cilium/config-map
                    startupProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9879
                        scheme: HTTP
                        httpHeaders:
                        - name: "brief"
                          value: "true"
                      failureThreshold: 105
                      periodSeconds: 2
                      successThreshold: 1
                      initialDelaySeconds: 5
                    livenessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9879
                        scheme: HTTP
                        httpHeaders:
                        - name: "brief"
                          value: "true"
                      periodSeconds: 30
                      successThreshold: 1
                      failureThreshold: 10
                      timeoutSeconds: 5
                    readinessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9879
                        scheme: HTTP
                        httpHeaders:
                        - name: "brief"
                          value: "true"
                      periodSeconds: 30
                      successThreshold: 1
                      failureThreshold: 3
                      timeoutSeconds: 5
                    env:
                    - name: K8S_NODE_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.nodeName
                    - name: CILIUM_K8S_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: CILIUM_CLUSTERMESH_CONFIG
                      value: /var/lib/cilium/clustermesh/
                    - name: GOMEMLIMIT
                      valueFrom:
                        resourceFieldRef:
                          resource: limits.memory
                          divisor: '1'
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    lifecycle:
                      postStart:
                        exec:
                          command:
                          - "bash"
                          - "-c"
                          - |
                                set -o errexit
                                set -o pipefail
                                set -o nounset
                                
                                # When running in AWS ENI mode, it's likely that 'aws-node' has
                                # had a chance to install SNAT iptables rules. These can result
                                # in dropped traffic, so we should attempt to remove them.
                                # We do it using a 'postStart' hook since this may need to run
                                # for nodes which might have already been init'ed but may still
                                # have dangling rules. This is safe because there are no
                                # dependencies on anything that is part of the startup script
                                # itself, and can be safely run multiple times per node (e.g. in
                                # case of a restart).
                                if [[ "$(iptables-save | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')" != "0" ]];
                                then
                                    echo 'Deleting iptables rules created by the AWS CNI VPC plugin'
                                    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN' | iptables-restore
                                fi
                                echo 'Done!'
                                
                      preStop:
                        exec:
                          command:
                          - /cni-uninstall.sh
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        add:
                          - CHOWN
                          - KILL
                          - NET_ADMIN
                          - NET_RAW
                          - IPC_LOCK
                          - SYS_ADMIN
                          - SYS_RESOURCE
                          - DAC_OVERRIDE
                          - FOWNER
                          - SETGID
                          - SETUID
                        drop:
                          - ALL
                    terminationMessagePolicy: FallbackToLogsOnError
                    volumeMounts:
                    - name: envoy-sockets
                      mountPath: /var/run/cilium/envoy/sockets
                      readOnly: false
                    # Unprivileged containers need to mount /proc/sys/net from the host
                    # to have write access
                    - mountPath: /host/proc/sys/net
                      name: host-proc-sys-net
                    # Unprivileged containers need to mount /proc/sys/kernel from the host
                    # to have write access
                    - mountPath: /host/proc/sys/kernel
                      name: host-proc-sys-kernel
                    - name: bpf-maps
                      mountPath: /sys/fs/bpf
                      # Unprivileged containers can't set mount propagation to bidirectional
                      # in this case we will mount the bpf fs from an init container that
                      # is privileged and set the mount propagation from host to container
                      # in Cilium.
                      mountPropagation: HostToContainer
                    # Check for duplicate mounts before mounting
                    - name: cilium-cgroup
                      mountPath: /sys/fs/cgroup
                    - name: cilium-run
                      mountPath: /var/run/cilium
                    - name: etc-cni-netd
                      mountPath: /host/etc/cni/net.d
                    - name: clustermesh-secrets
                      mountPath: /var/lib/cilium/clustermesh
                      readOnly: true
                      # Needed to be able to load kernel modules
                    - name: lib-modules
                      mountPath: /lib/modules
                      readOnly: true
                    - name: xtables-lock
                      mountPath: /run/xtables.lock
                    - name: tmp
                      mountPath: /tmp
                  initContainers:
                  - name: config
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    command:
                    - cilium-dbg
                    - build-config
                    env:
                    - name: K8S_NODE_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.nodeName
                    - name: CILIUM_K8S_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    volumeMounts:
                    - name: tmp
                      mountPath: /tmp
                    terminationMessagePolicy: FallbackToLogsOnError
                  - name: apply-sysctl-overwrites
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    env:
                    - name: BIN_PATH
                      value: /opt/cni/bin
                    command:
                    - sh
                    - -ec
                    # The statically linked Go program binary is invoked to avoid any
                    # dependency on utilities like sh that can be missing on certain
                    # distros installed on the underlying host. Copy the binary to the
                    # same directory where we install cilium cni plugin so that exec permissions
                    # are available.
                    - |
                      cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;
                      nsenter --mount=/hostproc/1/ns/mnt "${BIN_PATH}/cilium-sysctlfix";
                      rm /hostbin/cilium-sysctlfix
                    volumeMounts:
                    - name: hostproc
                      mountPath: /hostproc
                    - name: cni-path
                      mountPath: /hostbin
                    terminationMessagePolicy: FallbackToLogsOnError
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        add:
                          - SYS_ADMIN
                          - SYS_CHROOT
                          - SYS_PTRACE
                        drop:
                          - ALL
                  # Mount the bpf fs if it is not mounted. We will perform this task
                  # from a privileged container because the mount propagation bidirectional
                  # only works from privileged containers.
                  - name: mount-bpf-fs
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    args:
                    - 'mount | grep "/sys/fs/bpf type bpf" || mount -t bpf bpf /sys/fs/bpf'
                    command:
                    - /bin/bash
                    - -c
                    - --
                    terminationMessagePolicy: FallbackToLogsOnError
                    securityContext:
                      privileged: true
                    volumeMounts:
                    - name: bpf-maps
                      mountPath: /sys/fs/bpf
                      mountPropagation: Bidirectional
                  - name: clean-cilium-state
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    command:
                    - /init-container.sh
                    env:
                    - name: CILIUM_ALL_STATE
                      valueFrom:
                        configMapKeyRef:
                          name: cilium-config
                          key: clean-cilium-state
                          optional: true
                    - name: CILIUM_BPF_STATE
                      valueFrom:
                        configMapKeyRef:
                          name: cilium-config
                          key: clean-cilium-bpf-state
                          optional: true
                    - name: WRITE_CNI_CONF_WHEN_READY
                      valueFrom:
                        configMapKeyRef:
                          name: cilium-config
                          key: write-cni-conf-when-ready
                          optional: true
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    terminationMessagePolicy: FallbackToLogsOnError
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        add:
                          - NET_ADMIN
                          - SYS_ADMIN
                          - SYS_RESOURCE
                        drop:
                          - ALL
                    volumeMounts:
                    - name: bpf-maps
                      mountPath: /sys/fs/bpf
                      # Required to mount cgroup filesystem from the host to cilium agent pod
                    - name: cilium-cgroup
                      mountPath: /sys/fs/cgroup
                      mountPropagation: HostToContainer
                    - name: cilium-run
                      mountPath: /var/run/cilium # wait-for-kube-proxy
                  # Install the CNI binaries in an InitContainer so we don't have a writable host mount in the agent
                  - name: install-cni-binaries
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    command:
                      - "/install-plugin.sh"
                    resources:
                      requests:
                        cpu: 100m
                        memory: 10Mi
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        drop:
                          - ALL
                    terminationMessagePolicy: FallbackToLogsOnError
                    volumeMounts:
                      - name: cni-path
                        mountPath: /host/opt/cni/bin # .Values.cni.install
                  restartPolicy: Always
                  priorityClassName: system-node-critical
                  serviceAccountName: "cilium"
                  automountServiceAccountToken: true
                  terminationGracePeriodSeconds: 1
                  hostNetwork: true
                  affinity:
                    podAntiAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                      - labelSelector:
                          matchLabels:
                            k8s-app: cilium
                        topologyKey: kubernetes.io/hostname
                  nodeSelector:
                    kubernetes.io/os: linux
                  tolerations:
                    - operator: Exists
                  volumes:
                    # For sharing configuration between the "config" initContainer and the agent
                  - name: tmp
                    emptyDir: {}
                    # To keep state between restarts / upgrades
                  - name: cilium-run
                    hostPath:
                      path: /var/run/cilium
                      type: DirectoryOrCreate
                    # To keep state between restarts / upgrades for bpf maps
                  - name: bpf-maps
                    hostPath:
                      path: /sys/fs/bpf
                      type: DirectoryOrCreate
                  # To mount cgroup2 filesystem on the host or apply sysctlfix
                  - name: hostproc
                    hostPath:
                      path: /proc
                      type: Directory
                  # To keep state between restarts / upgrades for cgroup2 filesystem
                  - name: cilium-cgroup
                    hostPath:
                      path: /sys/fs/cgroup
                      type: DirectoryOrCreate
                  # To install cilium cni plugin in the host
                  - name: cni-path
                    hostPath:
                      path:  /opt/cni/bin
                      type: DirectoryOrCreate
                    # To install cilium cni configuration in the host
                  - name: etc-cni-netd
                    hostPath:
                      path: /etc/cni/net.d
                      type: DirectoryOrCreate
                    # To be able to load kernel modules
                  - name: lib-modules
                    hostPath:
                      path: /lib/modules
                    # To access iptables concurrently with other processes (e.g. kube-proxy)
                  - name: xtables-lock
                    hostPath:
                      path: /run/xtables.lock
                      type: FileOrCreate
                  # Sharing socket with Cilium Envoy on the same node by using a host path
                  - name: envoy-sockets
                    hostPath:
                      path: "/var/run/cilium/envoy/sockets"
                      type: DirectoryOrCreate
                    # To read the clustermesh configuration
                  - name: clustermesh-secrets
                    projected:
                      # note: the leading zero means this number is in octal representation: do not remove it
                      defaultMode: 0400
                      sources:
                      - secret:
                          name: cilium-clustermesh
                          optional: true
                          # note: items are not explicitly listed here, since the entries of this secret
                          # depend on the peers configured, and that would cause a restart of all agents
                          # at every addition/removal. Leaving the field empty makes each secret entry
                          # to be automatically projected into the volume as a file whose name is the key.
                      - secret:
                          name: clustermesh-apiserver-remote-cert
                          optional: true
                          items:
                          - key: tls.key
                            path: common-etcd-client.key
                          - key: tls.crt
                            path: common-etcd-client.crt
                          - key: ca.crt
                            path: common-etcd-client-ca.crt
                      # note: we configure the volume for the kvstoremesh-specific certificate
                      # regardless of whether KVStoreMesh is enabled or not, so that it can be
                      # automatically mounted in case KVStoreMesh gets subsequently enabled,
                      # without requiring an agent restart.
                      - secret:
                          name: clustermesh-apiserver-local-cert
                          optional: true
                          items:
                          - key: tls.key
                            path: local-etcd-client.key
                          - key: tls.crt
                            path: local-etcd-client.crt
                          - key: ca.crt
                            path: local-etcd-client-ca.crt
                  - name: host-proc-sys-net
                    hostPath:
                      path: /proc/sys/net
                      type: Directory
                  - name: host-proc-sys-kernel
                    hostPath:
                      path: /proc/sys/kernel
                      type: Directory
            ---
            # Source: cilium/templates/cilium-envoy/daemonset.yaml
            apiVersion: apps/v1
            kind: DaemonSet
            metadata:
              name: cilium-envoy
              namespace: kube-system
              labels:
                k8s-app: cilium-envoy
                app.kubernetes.io/part-of: cilium
                app.kubernetes.io/name: cilium-envoy
                name: cilium-envoy
            spec:
              selector:
                matchLabels:
                  k8s-app: cilium-envoy
              updateStrategy:
                rollingUpdate:
                  maxUnavailable: 2
                type: RollingUpdate
              template:
                metadata:
                  annotations:
                    prometheus.io/port: "9964"
                    prometheus.io/scrape: "true"
                  labels:
                    k8s-app: cilium-envoy
                    name: cilium-envoy
                    app.kubernetes.io/name: cilium-envoy
                    app.kubernetes.io/part-of: cilium
                spec:
                  securityContext:
                    appArmorProfile:
                      type: Unconfined
                  containers:
                  - name: cilium-envoy
                    image: "quay.io/cilium/cilium-envoy:v1.29.7-39a2a56bbd5b3a591f69dbca51d3e30ef97e0e51@sha256:bd5ff8c66716080028f414ec1cb4f7dc66f40d2fb5a009fff187f4a9b90b566b"
                    imagePullPolicy: IfNotPresent
                    command:
                    - /usr/bin/cilium-envoy-starter
                    args:
                    - '--'
                    - '-c /var/run/cilium/envoy/bootstrap-config.json'
                    - '--base-id 0'
                    - '--log-level info'
                    - '--log-format [%Y-%m-%d %T.%e][%t][%l][%n] [%g:%#] %v'
                    startupProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9878
                        scheme: HTTP
                      failureThreshold: 105
                      periodSeconds: 2
                      successThreshold: 1
                      initialDelaySeconds: 5
                    livenessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9878
                        scheme: HTTP
                      periodSeconds: 30
                      successThreshold: 1
                      failureThreshold: 10
                      timeoutSeconds: 5
                    readinessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9878
                        scheme: HTTP
                      periodSeconds: 30
                      successThreshold: 1
                      failureThreshold: 3
                      timeoutSeconds: 5
                    env:
                    - name: K8S_NODE_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.nodeName
                    - name: CILIUM_K8S_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    ports:
                    - name: envoy-metrics
                      containerPort: 9964
                      hostPort: 9964
                      protocol: TCP
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        add:
                          - NET_ADMIN
                          - SYS_ADMIN
                        drop:
                          - ALL
                    terminationMessagePolicy: FallbackToLogsOnError
                    volumeMounts:
                    - name: envoy-sockets
                      mountPath: /var/run/cilium/envoy/sockets
                      readOnly: false
                    - name: envoy-artifacts
                      mountPath: /var/run/cilium/envoy/artifacts
                      readOnly: true
                    - name: envoy-config
                      mountPath: /var/run/cilium/envoy/
                      readOnly: true
                    - name: bpf-maps
                      mountPath: /sys/fs/bpf
                      mountPropagation: HostToContainer
                  restartPolicy: Always
                  priorityClassName: system-node-critical
                  serviceAccountName: "cilium-envoy"
                  automountServiceAccountToken: true
                  terminationGracePeriodSeconds: 1
                  hostNetwork: true
                  affinity:
                    nodeAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                        nodeSelectorTerms:
                        - matchExpressions:
                          - key: cilium.io/no-schedule
                            operator: NotIn
                            values:
                            - "true"
                    podAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                      - labelSelector:
                          matchLabels:
                            k8s-app: cilium
                        topologyKey: kubernetes.io/hostname
                    podAntiAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                      - labelSelector:
                          matchLabels:
                            k8s-app: cilium-envoy
                        topologyKey: kubernetes.io/hostname
                  nodeSelector:
                    kubernetes.io/os: linux
                  tolerations:
                    - operator: Exists
                  volumes:
                  - name: envoy-sockets
                    hostPath:
                      path: "/var/run/cilium/envoy/sockets"
                      type: DirectoryOrCreate
                  - name: envoy-artifacts
                    hostPath:
                      path: "/var/run/cilium/envoy/artifacts"
                      type: DirectoryOrCreate
                  - name: envoy-config
                    configMap:
                      name: cilium-envoy-config
                      # note: the leading zero means this number is in octal representation: do not remove it
                      defaultMode: 0400
                      items:
                        - key: bootstrap-config.json
                          path: bootstrap-config.json
                    # To keep state between restarts / upgrades
                    # To keep state between restarts / upgrades for bpf maps
                  - name: bpf-maps
                    hostPath:
                      path: /sys/fs/bpf
                      type: DirectoryOrCreate
            ---
            # Source: cilium/templates/cilium-operator/deployment.yaml
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: cilium-operator
              namespace: kube-system
              labels:
                io.cilium/app: operator
                name: cilium-operator
                app.kubernetes.io/part-of: cilium
                app.kubernetes.io/name: cilium-operator
            spec:
              # See docs on ServerCapabilities.LeasesResourceLock in file pkg/k8s/version/version.go
              # for more details.
              replicas: 2
              selector:
                matchLabels:
                  io.cilium/app: operator
                  name: cilium-operator
              # ensure operator update on single node k8s clusters, by using rolling update with maxUnavailable=100% in case
              # of one replica and no user configured Recreate strategy.
              # otherwise an update might get stuck due to the default maxUnavailable=50% in combination with the
              # podAntiAffinity which prevents deployments of multiple operator replicas on the same node.
              strategy:
                rollingUpdate:
                  maxSurge: 25%
                  maxUnavailable: 50%
                type: RollingUpdate
              template:
                metadata:
                  annotations:
                    prometheus.io/port: "9963"
                    prometheus.io/scrape: "true"
                  labels:
                    io.cilium/app: operator
                    name: cilium-operator
                    app.kubernetes.io/part-of: cilium
                    app.kubernetes.io/name: cilium-operator
                spec:
                  containers:
                  - name: cilium-operator
                    image: "quay.io/cilium/operator-generic:v1.16.1@sha256:3bc7e7a43bc4a4d8989cb7936c5d96675dd2d02c306adf925ce0a7c35aa27dc4"
                    imagePullPolicy: IfNotPresent
                    command:
                    - cilium-operator-generic
                    args:
                    - --config-dir=/tmp/cilium/config-map
                    - --debug=$(CILIUM_DEBUG)
                    env:
                    - name: K8S_NODE_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.nodeName
                    - name: CILIUM_K8S_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: CILIUM_DEBUG
                      valueFrom:
                        configMapKeyRef:
                          key: debug
                          name: cilium-config
                          optional: true
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    ports:
                    - name: prometheus
                      containerPort: 9963
                      hostPort: 9963
                      protocol: TCP
                    livenessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9234
                        scheme: HTTP
                      initialDelaySeconds: 60
                      periodSeconds: 10
                      timeoutSeconds: 3
                    readinessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9234
                        scheme: HTTP
                      initialDelaySeconds: 0
                      periodSeconds: 5
                      timeoutSeconds: 3
                      failureThreshold: 5
                    volumeMounts:
                    - name: cilium-config-path
                      mountPath: /tmp/cilium/config-map
                      readOnly: true
                    terminationMessagePolicy: FallbackToLogsOnError
                  hostNetwork: true
                  restartPolicy: Always
                  priorityClassName: system-cluster-critical
                  serviceAccountName: "cilium-operator"
                  automountServiceAccountToken: true
                  # In HA mode, cilium-operator pods must not be scheduled on the same
                  # node as they will clash with each other.
                  affinity:
                    podAntiAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                      - labelSelector:
                          matchLabels:
                            io.cilium/app: operator
                        topologyKey: kubernetes.io/hostname
                  nodeSelector:
                    kubernetes.io/os: linux
                  tolerations:
                    - operator: Exists
                  volumes:
                    # To read the configuration from the config map
                  - name: cilium-config-path
                    configMap:
                      name: cilium-config
    
    # # A key used for the [encryption of secret data at rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).

    # # Decryption secret example (do not use in production!).
    # aescbcEncryptionSecret: z01mye6j16bspJYtTB/5SFX8j7Ph4JXxM2Xuu4vsBPM=

    # # Core DNS specific configuration options.
    # coreDNS:
    #     image: registry.k8s.io/coredns/coredns:v1.12.4 # The `image` field is an override to the default coredns image.

    # # External cloud provider configuration.
    # externalCloudProvider:
    #     enabled: true # Enable external cloud provider.
    #     # A list of urls that point to additional manifests for an external cloud provider.
    #     manifests:
    #         - https://raw.githubusercontent.com/kubernetes/cloud-provider-aws/v1.20.0-alpha.0/manifests/rbac.yaml
    #         - https://raw.githubusercontent.com/kubernetes/cloud-provider-aws/v1.20.0-alpha.0/manifests/aws-cloud-controller-manager-daemonset.yaml

    # # A list of urls that point to additional manifests.
    # extraManifests:
    #     - https://www.example.com/manifest1.yaml
    #     - https://www.example.com/manifest2.yaml

    # # A map of key value pairs that will be added while fetching the extraManifests.
    # extraManifestHeaders:
    #     Token: "1234567"
    #     X-ExtraInfo: info

    # # A list of inline Kubernetes manifests.
    # inlineManifests:
    #     - name: namespace-ci # Name of the manifest.
    #       contents: |- # Manifest contents as a string.
    #         apiVersion: v1
    #         kind: Namespace
    #         metadata:
    #         	name: ci

    # # Settings for admin kubeconfig generation.
    # adminKubeconfig:
    #     certLifetime: 1h0m0s # Admin kubeconfig certificate lifetime (default is 1 year).
