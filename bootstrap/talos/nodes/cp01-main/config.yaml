version: v1alpha1 # Indicates the schema used to decode the contents.
debug: false # Enable verbose logging to the console.
persist: true
# Provides machine specific configuration options.
machine:
    type: controlplane # Defines the role of the machine within the cluster.
    token: 3ct9rw.8nxvwrxkwjfytql5 # The `token` is used by a machine to join the PKI of the cluster.
    # The root certificate authority of the PKI.
    ca:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJQakNCOGFBREFnRUNBaEJWZ2hyNkZnWkllV2psRzcvQzgrWVBNQVVHQXl0bGNEQVFNUTR3REFZRFZRUUsKRXdWMFlXeHZjekFlRncweU5URXlNRFl3TlRFMU1UZGFGdzB6TlRFeU1EUXdOVEUxTVRkYU1CQXhEakFNQmdOVgpCQW9UQlhSaGJHOXpNQ293QlFZREsyVndBeUVBc3E3UUI3emJrdjZpdHJKR0FUc3hkZk1rUmlvajRqcE1TcDNYCmlWOWlXcjJqWVRCZk1BNEdBMVVkRHdFQi93UUVBd0lDaERBZEJnTlZIU1VFRmpBVUJnZ3JCZ0VGQlFjREFRWUkKS3dZQkJRVUhBd0l3RHdZRFZSMFRBUUgvQkFVd0F3RUIvekFkQmdOVkhRNEVGZ1FVZjRaQ3djdW5FVCt1cmcwRwo4RFJFcXhiMzMwZ3dCUVlESzJWd0EwRUF5d01sSkZ4R0UzZVorKzBaUWt0eGFrTTExZFlKbE44c2FtT1RxZFg3CndzakNpbUw0WDVvZWdBbklSU0xCaHhGNHhoUjBQdWtjKzVMaEkxc3M0blRpQmc9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFRDI1NTE5IFBSSVZBVEUgS0VZLS0tLS0KTUM0Q0FRQXdCUVlESzJWd0JDSUVJRzN2SWxmUXBGRHhZUVB2ZldsV1Rsem42TnY2RDJhUGRLN1ZvQ2hIZGYrZAotLS0tLUVORCBFRDI1NTE5IFBSSVZBVEUgS0VZLS0tLS0K
    # Extra certificate subject alternative names for the machine's certificate.
    certSANs: []
    #   # Uncomment this to enable SANs.
    #   - 10.0.0.10
    #   - 172.16.0.10
    #   - 192.168.0.10

    # Used to provide additional options to the kubelet.
    kubelet:
        image: ghcr.io/siderolabs/kubelet:v1.34.2 # The `image` field is an optional reference to an alternative kubelet image.
        defaultRuntimeSeccompProfileEnabled: true # Enable container runtime default Seccomp profile.
        disableManifestsDirectory: true # The `disableManifestsDirectory` field configures the kubelet to get static pod manifests from the /etc/kubernetes/manifests directory.
        
        # # The `ClusterDNS` field is an optional reference to an alternative kubelet clusterDNS ip list.
        # clusterDNS:
        #     - 10.96.0.10
        #     - 169.254.2.53

        # # The `extraArgs` field is used to provide additional flags to the kubelet.
        # extraArgs:
        #     key: value

        # # The `extraMounts` field is used to add additional mounts to the kubelet container.
        # extraMounts:
        #     - destination: /var/lib/example # Destination is the absolute path where the mount will be placed in the container.
        #       type: bind # Type specifies the mount kind.
        #       source: /var/lib/example # Source specifies the source path of the mount.
        #       # Options are fstab style mount options.
        #       options:
        #         - bind
        #         - rshared
        #         - rw

        # # The `extraConfig` field is used to provide kubelet configuration overrides.
        # extraConfig:
        #     serverTLSBootstrap: true

        # # The `KubeletCredentialProviderConfig` field is used to provide kubelet credential configuration.
        # credentialProviderConfig:
        #     apiVersion: kubelet.config.k8s.io/v1
        #     kind: CredentialProviderConfig
        #     providers:
        #         - apiVersion: credentialprovider.kubelet.k8s.io/v1
        #           defaultCacheDuration: 12h
        #           matchImages:
        #             - '*.dkr.ecr.*.amazonaws.com'
        #             - '*.dkr.ecr.*.amazonaws.com.cn'
        #             - '*.dkr.ecr-fips.*.amazonaws.com'
        #             - '*.dkr.ecr.us-iso-east-1.c2s.ic.gov'
        #             - '*.dkr.ecr.us-isob-east-1.sc2s.sgov.gov'
        #           name: ecr-credential-provider

        # # The `nodeIP` field is used to configure `--node-ip` flag for the kubelet.
        # nodeIP:
        #     # The `validSubnets` field configures the networks to pick kubelet node IP from.
        #     validSubnets:
        #         - 10.0.0.0/8
        #         - '!10.0.0.3/32'
        #         - fdc7::/16
    # Provides machine specific network configuration options.
    network: {}
    # # `interfaces` is used to define the network interface configuration.
    # interfaces:
    #     - interface: enp0s1 # The interface name.
    #       # Assigns static IP addresses to the interface.
    #       addresses:
    #         - 192.168.2.0/24
    #       # A list of routes associated with the interface.
    #       routes:
    #         - network: 0.0.0.0/0 # The route's network (destination).
    #           gateway: 192.168.2.1 # The route's gateway (if empty, creates link scope route).
    #           metric: 1024 # The optional metric for the route.
    #       mtu: 1500 # The interface's MTU.
    #       
    #       # # Picks a network device using the selector.

    #       # # select a device with bus prefix 00:*.
    #       # deviceSelector:
    #       #     busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       # # select a device with mac address matching `*:f0:ab` and `virtio` kernel driver.
    #       # deviceSelector:
    #       #     hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #     driver: virtio_net # Kernel driver, supports matching by wildcard.
    #       # # select a device with bus prefix 00:*, a device with mac address matching `*:f0:ab` and `virtio` kernel driver.
    #       # deviceSelector:
    #       #     - busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       #     - hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #       driver: virtio_net # Kernel driver, supports matching by wildcard.

    #       # # Bond specific options.
    #       # bond:
    #       #     # The interfaces that make up the bond.
    #       #     interfaces:
    #       #         - enp2s0
    #       #         - enp2s1
    #       #     # Picks a network device using the selector.
    #       #     deviceSelectors:
    #       #         - busPath: 00:* # PCI, USB bus prefix, supports matching by wildcard.
    #       #         - hardwareAddr: '*:f0:ab' # Device hardware (MAC) address, supports matching by wildcard.
    #       #           driver: virtio_net # Kernel driver, supports matching by wildcard.
    #       #     mode: 802.3ad # A bond option.
    #       #     lacpRate: fast # A bond option.

    #       # # Bridge specific options.
    #       # bridge:
    #       #     # The interfaces that make up the bridge.
    #       #     interfaces:
    #       #         - enxda4042ca9a51
    #       #         - enxae2a6774c259
    #       #     # Enable STP on this bridge.
    #       #     stp:
    #       #         enabled: true # Whether Spanning Tree Protocol (STP) is enabled.

    #       # # Configure this device as a bridge port.
    #       # bridgePort:
    #       #     master: br0 # The name of the bridge master interface

    #       # # Indicates if DHCP should be used to configure the interface.
    #       # dhcp: true

    #       # # DHCP specific options.
    #       # dhcpOptions:
    #       #     routeMetric: 1024 # The priority of all routes received via DHCP.

    #       # # Wireguard specific configuration.

    #       # # wireguard server example
    #       # wireguard:
    #       #     privateKey: ABCDEF... # Specifies a private key configuration (base64 encoded).
    #       #     listenPort: 51111 # Specifies a device's listening port.
    #       #     # Specifies a list of peer configurations to apply to a device.
    #       #     peers:
    #       #         - publicKey: ABCDEF... # Specifies the public key of this peer.
    #       #           endpoint: 192.168.1.3 # Specifies the endpoint of this peer entry.
    #       #           # AllowedIPs specifies a list of allowed IP addresses in CIDR notation for this peer.
    #       #           allowedIPs:
    #       #             - 192.168.1.0/24
    #       # # wireguard peer example
    #       # wireguard:
    #       #     privateKey: ABCDEF... # Specifies a private key configuration (base64 encoded).
    #       #     # Specifies a list of peer configurations to apply to a device.
    #       #     peers:
    #       #         - publicKey: ABCDEF... # Specifies the public key of this peer.
    #       #           endpoint: 192.168.1.2:51822 # Specifies the endpoint of this peer entry.
    #       #           persistentKeepaliveInterval: 10s # Specifies the persistent keepalive interval for this peer.
    #       #           # AllowedIPs specifies a list of allowed IP addresses in CIDR notation for this peer.
    #       #           allowedIPs:
    #       #             - 192.168.1.0/24

    #       # # Virtual (shared) IP address configuration.

    #       # # layer2 vip example
    #       # vip:
    #       #     ip: 172.16.199.55 # Specifies the IP address to be used.

    # # Used to statically set the nameservers for the machine.
    # nameservers:
    #     - 8.8.8.8
    #     - 1.1.1.1

    # # Used to statically set arbitrary search domains.
    # searchDomains:
    #     - example.org
    #     - example.com

    # # Allows for extra entries to be added to the `/etc/hosts` file
    # extraHostEntries:
    #     - ip: 192.168.1.100 # The IP of the host.
    #       # The host alias.
    #       aliases:
    #         - example
    #         - example.domain.tld

    # # Configures KubeSpan feature.
    # kubespan:
    #     enabled: true # Enable the KubeSpan feature.

    # Used to provide instructions for installations.
    install:
        disk: /dev/sda # The disk used for installations.
        image: ghcr.io/siderolabs/installer:v1.11.5 # Allows for supplying the image used to perform the installation.
        wipe: false # Indicates if the installation disk should be wiped at installation time.
        
        # # Look up disk using disk attributes like model, size, serial and others.
        # diskSelector:
        #     size: 4GB # Disk size.
        #     model: WDC* # Disk model `/sys/block/<dev>/device/model`.
        #     busPath: /pci0000:00/0000:00:17.0/ata1/host0/target0:0:0/0:0:0:0 # Disk bus path.

        # # Allows for supplying extra kernel args via the bootloader.
        # extraKernelArgs:
        #     - talos.platform=metal
        #     - reboot=k
    # Used to configure the machine's container image registry mirrors.
    registries: {}
    # # Specifies mirror configuration for each registry host namespace.
    # mirrors:
    #     ghcr.io:
    #         # List of endpoints (URLs) for registry mirrors to use.
    #         endpoints:
    #             - https://registry.insecure
    #             - https://ghcr.io/v2/

    # # Specifies TLS & auth configuration for HTTPS image registries.
    # config:
    #     registry.insecure:
    #         # The TLS configuration for the registry.
    #         tls:
    #             insecureSkipVerify: true # Skip TLS server certificate verification (not recommended).
    #             
    #             # # Enable mutual TLS authentication with the registry.
    #             # clientIdentity:
    #             #     crt: LS0tIEVYQU1QTEUgQ0VSVElGSUNBVEUgLS0t
    #             #     key: LS0tIEVYQU1QTEUgS0VZIC0tLQ==
    #         
    #         # # The auth configuration for this registry.
    #         # auth:
    #         #     username: username # Optional registry authentication.
    #         #     password: password # Optional registry authentication.

    # Features describe individual Talos features that can be switched on or off.
    features:
        rbac: true # Enable role-based access control (RBAC).
        stableHostname: true # Enable stable default hostname.
        apidCheckExtKeyUsage: true # Enable checks for extended key usage of client certificates in apid.
        diskQuotaSupport: true # Enable XFS project quota support for EPHEMERAL partition and user disks.
        # KubePrism - local proxy/load balancer on defined port that will distribute
        kubePrism:
            enabled: true # Enable KubePrism support - will start local load balancing proxy.
            port: 7445 # KubePrism port.
        # Configures host DNS caching resolver.
        hostDNS:
            enabled: true # Enable host DNS caching resolver.
            forwardKubeDNSToHost: true # Use the host DNS resolver as upstream for Kubernetes CoreDNS pods.
        
        # # Configure Talos API access from Kubernetes pods.
        # kubernetesTalosAPIAccess:
        #     enabled: true # Enable Talos API access from Kubernetes pods.
        #     # The list of Talos API roles which can be granted for access from Kubernetes pods.
        #     allowedRoles:
        #         - os:reader
        #     # The list of Kubernetes namespaces Talos API access is available from.
        #     allowedKubernetesNamespaces:
        #         - kube-system
    # Configures the node labels for the machine.
    nodeLabels:
        node.kubernetes.io/exclude-from-external-load-balancers: ""
    
    # # Provides machine specific control plane configuration options.

    # # ControlPlane definition example.
    # controlPlane:
    #     # Controller manager machine specific configuration options.
    #     controllerManager:
    #         disabled: false # Disable kube-controller-manager on the node.
    #     # Scheduler machine specific configuration options.
    #     scheduler:
    #         disabled: true # Disable kube-scheduler on the node.

    # # Used to provide static pod definitions to be run by the kubelet directly bypassing the kube-apiserver.

    # # nginx static pod.
    # pods:
    #     - apiVersion: v1
    #       kind: pod
    #       metadata:
    #         name: nginx
    #       spec:
    #         containers:
    #             - image: nginx
    #               name: nginx

    # # Allows the addition of user specified files.

    # # MachineFiles usage example.
    # files:
    #     - content: '...' # The contents of the file.
    #       permissions: 0o666 # The file's permissions in octal.
    #       path: /tmp/file.txt # The path of the file.
    #       op: append # The operation to use

    # # The `env` field allows for the addition of environment variables.

    # # Environment variables definition examples.
    # env:
    #     GRPC_GO_LOG_SEVERITY_LEVEL: info
    #     GRPC_GO_LOG_VERBOSITY_LEVEL: "99"
    #     https_proxy: http://SERVER:PORT/
    # env:
    #     GRPC_GO_LOG_SEVERITY_LEVEL: error
    #     https_proxy: https://USERNAME:PASSWORD@SERVER:PORT/
    # env:
    #     https_proxy: http://DOMAIN\USERNAME:PASSWORD@SERVER:PORT/

    # # Used to configure the machine's time settings.

    # # Example configuration for cloudflare ntp server.
    # time:
    #     disabled: false # Indicates if the time service is disabled for the machine.
    #     # description: |
    #     servers:
    #         - time.cloudflare.com
    #     bootTimeout: 2m0s # Specifies the timeout when the node time is considered to be in sync unlocking the boot sequence.

    # # Used to configure the machine's sysctls.

    # # MachineSysctls usage example.
    # sysctls:
    #     kernel.domainname: talos.dev
    #     net.ipv4.ip_forward: "0"
    #     net/ipv6/conf/eth0.100/disable_ipv6: "1"

    # # Used to configure the machine's sysfs.

    # # MachineSysfs usage example.
    # sysfs:
    #     devices.system.cpu.cpu0.cpufreq.scaling_governor: performance

    # # Configures the udev system.
    # udev:
    #     # List of udev rules to apply to the udev system
    #     rules:
    #         - SUBSYSTEM=="drm", KERNEL=="renderD*", GROUP="44", MODE="0660"

    # # Configures the logging system.
    # logging:
    #     # Logging destination.
    #     destinations:
    #         - endpoint: tcp://1.2.3.4:12345 # Where to send logs. Supported protocols are "tcp" and "udp".
    #           format: json_lines # Logs format.

    # # Configures the kernel.
    # kernel:
    #     # Kernel modules to load.
    #     modules:
    #         - name: brtfs # Module name.

    # # Configures the seccomp profiles for the machine.
    # seccompProfiles:
    #     - name: audit.json # The `name` field is used to provide the file name of the seccomp profile.
    #       # The `value` field is used to provide the seccomp profile.
    #       value:
    #         defaultAction: SCMP_ACT_LOG

    # # Override (patch) settings in the default OCI runtime spec for CRI containers.

    # # override default open file limit
    # baseRuntimeSpecOverrides:
    #     process:
    #         rlimits:
    #             - hard: 1024
    #               soft: 1024
    #               type: RLIMIT_NOFILE

    # # Configures the node annotations for the machine.

    # # node annotations example.
    # nodeAnnotations:
    #     customer.io/rack: r13a25

    # # Configures the node taints for the machine. Effect is optional.

    # # node taints example.
    # nodeTaints:
    #     exampleTaint: exampleTaintValue:NoSchedule
# Provides cluster specific configuration options.
cluster:
    id: qGRdELNhQxqHetY-npGPLe7hIX_ZfjEikbMCX0AYQoA= # Globally unique identifier for this cluster (base64 encoded random 32 bytes).
    secret: LOuAzLsLUSXmY+tqNgHkBYr41ec08uonQNjx109xPuE= # Shared secret of cluster (base64 encoded random 32 bytes).
    # Provides control plane specific configuration options.
    controlPlane:
        endpoint: https://95.216.151.243:6443 # Endpoint is the canonical controlplane endpoint, which can be an IP address or a DNS hostname.
    clusterName: bizmatters-dev-01 # Configures the cluster's name.
    # Provides cluster specific network configuration options.
    network:
        dnsDomain: cluster.local # The domain used by Kubernetes DNS.
        # The pod subnet CIDR.
        podSubnets:
            - 10.244.0.0/16
        # The service subnet CIDR.
        serviceSubnets:
            - 10.96.0.0/12
        
        # # The CNI used.
        # cni:
        #     name: custom # Name of CNI to use.
        #     # URLs containing manifests to apply for the CNI.
        #     urls:
        #         - https://docs.projectcalico.org/archive/v3.20/manifests/canal.yaml
    token: 8j6aqs.fzfdsdc28hhhgg39 # The [bootstrap token](https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/) used to join the cluster.
    secretboxEncryptionSecret: 2QT37tGY9POYz0AuukTa/79A/6tmft5Yo04g1QvZ9zE= # A key used for the [encryption of secret data at rest](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).
    # The base64 encoded root certificate authority used by Kubernetes.
    ca:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJpekNDQVRDZ0F3SUJBZ0lSQUpHSVZELzkyUi9yd3FsVDdDZXF6Nmt3Q2dZSUtvWkl6ajBFQXdJd0ZURVQKTUJFR0ExVUVDaE1LYTNWaVpYSnVaWFJsY3pBZUZ3MHlOVEV5TURZd05URTFNVGRhRncwek5URXlNRFF3TlRFMQpNVGRhTUJVeEV6QVJCZ05WQkFvVENtdDFZbVZ5Ym1WMFpYTXdXVEFUQmdjcWhrak9QUUlCQmdncWhrak9QUU1CCkJ3TkNBQVMrT2pLZkdSbHF0a1FvcVVUR2h4RWxRbDNQTk9zTzRQeTZVQWs1MG93bExmVDhYQnhZQkhPemdXSzAKYVRNQVRSUEVGZ3FsejBQS0NUMVRGanllb1ByWW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXdIUVlEVlIwbApCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0hRWURWUjBPCkJCWUVGQ0RUdzBDZ0tyTjNrd1lxMWtYTVNwQ0xTdUZOTUFvR0NDcUdTTTQ5QkFNQ0Ewa0FNRVlDSVFEalE1UjgKbnQyUkFabUJNdEpuZjlOelV2NVdLUkEvSktVT3BNQUl4NmM1ckFJaEFPOVJYMTJwZTkzcFZSbnFGcEJRK09Idwp4SWN3THE0elFtS2h0TDYzSGJqbQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSVA3YzBTTmxnUE5uemdlYWlDNnpEVTZBQ0NOcGpMOWtCVnlHQmc4dWtNRFZvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFdmpveW54a1phclpFS0tsRXhvY1JKVUpkenpUckR1RDh1bEFKT2RLTUpTMzAvRndjV0FSegpzNEZpdEdrekFFMFR4QllLcGM5RHlnazlVeFk4bnFENjJBPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    # The base64 encoded aggregator certificate authority used by Kubernetes for front-proxy certificate generation.
    aggregatorCA:
        crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJZRENDQVFhZ0F3SUJBZ0lSQUsvSnVGRFhjOVJTOVYwNDNlZEhaRDB3Q2dZSUtvWkl6ajBFQXdJd0FEQWUKRncweU5URXlNRFl3TlRFMU1UZGFGdzB6TlRFeU1EUXdOVEUxTVRkYU1BQXdXVEFUQmdjcWhrak9QUUlCQmdncQpoa2pPUFFNQkJ3TkNBQVNEYm83UEdtaVgxNUZWQTZXVmRveFNVVXRsaE9QdkJIYlNxZ1hoK2tVbllFVjBkUUExCnlYbERYZDhTYTZOdXZTcGlqWVlDOGVybVdYZU1od2FTQXJhcW8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FvUXcKSFFZRFZSMGxCQll3RkFZSUt3WUJCUVVIQXdFR0NDc0dBUVVGQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4dwpIUVlEVlIwT0JCWUVGS3A4Si9sQjhuVWc4b01CM3NLSllvQk5nd3crTUFvR0NDcUdTTTQ5QkFNQ0EwZ0FNRVVDCklRRHF1d3ZyWnZHUHlUeHdUaWFSY3NKajBIRG9Zek5TUzdIVDBZVzdnTHRXS0FJZ1lnOWpBejZ4VTF2RmxiTjIKck1PVVd1TnZ5TkhKS1dlVTdZVEx6OThlYVFBPQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
        key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSU9RK0g5WWwzN2NiOENnei9NdFh6VUV3ZmcxNmRwdG9LYzZOUDNtZkhKRjVvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFZzI2T3p4cG9sOWVSVlFPbGxYYU1VbEZMWllUajd3UjIwcW9GNGZwRkoyQkZkSFVBTmNsNQpRMTNmRW11amJyMHFZbzJHQXZIcTVsbDNqSWNHa2dLMnFnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
    # The base64 encoded private key for service account token generation.
    serviceAccount:
        key: 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
    # API server specific configuration options.
    apiServer:
        image: registry.k8s.io/kube-apiserver:v1.34.2 # The container image used in the API server manifest.
        # Extra certificate subject alternative names for the API server's certificate.
        certSANs:
            - 46.62.218.181
        disablePodSecurityPolicy: true # Disable PodSecurityPolicy in the API server and default manifests.
        # Configure the API server admission plugins.
        admissionControl:
            - name: PodSecurity # Name is the name of the admission controller.
              # Configuration is an embedded configuration object to be used as the plugin's
              configuration:
                apiVersion: pod-security.admission.config.k8s.io/v1alpha1
                defaults:
                    audit: restricted
                    audit-version: latest
                    enforce: baseline
                    enforce-version: latest
                    warn: restricted
                    warn-version: latest
                exemptions:
                    namespaces:
                        - kube-system
                    runtimeClasses: []
                    usernames: []
                kind: PodSecurityConfiguration
        # Configure the API server audit policy.
        auditPolicy:
            apiVersion: audit.k8s.io/v1
            kind: Policy
            rules:
                - level: Metadata
        
        # # Configure the API server authorization config. Node and RBAC authorizers are always added irrespective of the configuration.
        # authorizationConfig:
        #     - type: Webhook # Type is the name of the authorizer. Allowed values are `Node`, `RBAC`, and `Webhook`.
        #       name: webhook # Name is used to describe the authorizer.
        #       # webhook is the configuration for the webhook authorizer.
        #       webhook:
        #         connectionInfo:
        #             type: InClusterConfig
        #         failurePolicy: Deny
        #         matchConditionSubjectAccessReviewVersion: v1
        #         matchConditions:
        #             - expression: has(request.resourceAttributes)
        #             - expression: '!(\''system:serviceaccounts:kube-system\'' in request.groups)'
        #         subjectAccessReviewVersion: v1
        #         timeout: 3s
        #     - type: Webhook # Type is the name of the authorizer. Allowed values are `Node`, `RBAC`, and `Webhook`.
        #       name: in-cluster-authorizer # Name is used to describe the authorizer.
        #       # webhook is the configuration for the webhook authorizer.
        #       webhook:
        #         connectionInfo:
        #             type: InClusterConfig
        #         failurePolicy: NoOpinion
        #         matchConditionSubjectAccessReviewVersion: v1
        #         subjectAccessReviewVersion: v1
        #         timeout: 3s
    # Controller manager server specific configuration options.
    controllerManager:
        image: registry.k8s.io/kube-controller-manager:v1.34.2 # The container image used in the controller manager manifest.
    # Kube-proxy server-specific configuration options
    proxy:
        image: registry.k8s.io/kube-proxy:v1.34.2 # The container image used in the kube-proxy manifest.
        
        # # Disable kube-proxy deployment on cluster bootstrap.
        # disabled: false
    # Scheduler server specific configuration options.
    scheduler:
        image: registry.k8s.io/kube-scheduler:v1.34.2 # The container image used in the scheduler manifest.
    # Configures cluster member discovery.
    discovery:
        enabled: true # Enable the cluster membership discovery feature.
        # Configure registries used for cluster member discovery.
        registries:
            # Kubernetes registry uses Kubernetes API server to discover cluster members and stores additional information
            kubernetes:
                disabled: true # Disable Kubernetes discovery registry.
            # Service registry is using an external service to push and pull information about cluster members.
            service: {}
            # # External service endpoint.
            # endpoint: https://discovery.talos.dev/
    # Etcd specific configuration options.
    etcd:
        # The `ca` is the root certificate authority of the PKI.
        ca:
            crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJmakNDQVNTZ0F3SUJBZ0lSQU1sYm5lWWk3TWNKOHhxeHNlU0EzcEF3Q2dZSUtvWkl6ajBFQXdJd0R6RU4KTUFzR0ExVUVDaE1FWlhSalpEQWVGdzB5TlRFeU1EWXdOVEUxTVRkYUZ3MHpOVEV5TURRd05URTFNVGRhTUE4eApEVEFMQmdOVkJBb1RCR1YwWTJRd1dUQVRCZ2NxaGtqT1BRSUJCZ2dxaGtqT1BRTUJCd05DQUFRTVd1SGVVMUpKCmRKcHhSZ1BtMWt3aEhBQjBaREw0eEJQcmdZQ0tKNEVCT2hSRGRoUmovRXFvSzVkaElqWFNjVmFZMkZyVVFVNHkKT1ZWQVA3SDQyUEd4bzJFd1h6QU9CZ05WSFE4QkFmOEVCQU1DQW9Rd0hRWURWUjBsQkJZd0ZBWUlLd1lCQlFVSApBd0VHQ0NzR0FRVUZCd01DTUE4R0ExVWRFd0VCL3dRRk1BTUJBZjh3SFFZRFZSME9CQllFRklYWUhnbDByaG1vCmNGc20rZSsxNkZCMlpLTjlNQW9HQ0NxR1NNNDlCQU1DQTBnQU1FVUNJUUNZanpkWDNhU0xjL2lkbVdERXVUeEwKWWN1ZlZSNTR3UkNUQ2RhUUpOdzJaUUlnY2tLM3YvYUVRbHRnbHdkUlc0bVJ2dDU4SUg4Zm9RK2NodGpwZUs5Ywo4d1k9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
            key: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSURNRFhtL1lCeVg5Q0hkWG42QlJwWmZkQXkwMUlBUzRncGh4TDBoZi9lMlpvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFREZyaDNsTlNTWFNhY1VZRDV0Wk1JUndBZEdReStNUVQ2NEdBaWllQkFUb1VRM1lVWS94SwpxQ3VYWVNJMTBuRldtTmhhMUVGT01qbFZRRCt4K05qeHNRPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=
        
        # # The container image used to create the etcd service.
        # image: gcr.io/etcd-development/etcd:v3.6.5

        # # The `advertisedSubnets` field configures the networks to pick etcd advertised IP from.
        # advertisedSubnets:
        #     - 10.0.0.0/8
    allowSchedulingOnControlPlanes: false # Prevents running workload on control-plane nodes.
    # Cilium CNI for bootstrap - minimal config
    # ArgoCD will adopt and enable full features (Hubble, Gateway API)
    inlineManifests:
        - name: cilium-bootstrap
          contents: |
            ---
            # Source: cilium/templates/cilium-agent/serviceaccount.yaml
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: "cilium"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-envoy/serviceaccount.yaml
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: "cilium-envoy"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-operator/serviceaccount.yaml
            apiVersion: v1
            kind: ServiceAccount
            metadata:
              name: "cilium-operator"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-configmap.yaml
            apiVersion: v1
            kind: ConfigMap
            metadata:
              name: cilium-config
              namespace: kube-system
            data:
            
              # Identity allocation mode selects how identities are shared between cilium
              # nodes by setting how they are stored. The options are "crd" or "kvstore".
              # - "crd" stores identities in kubernetes as CRDs (custom resource definition).
              #   These can be queried with:
              #     kubectl get ciliumid
              # - "kvstore" stores identities in an etcd kvstore, that is
              #   configured below. Cilium versions before 1.6 supported only the kvstore
              #   backend. Upgrades from these older cilium versions should continue using
              #   the kvstore by commenting out the identity-allocation-mode below, or
              #   setting it to "kvstore".
              identity-allocation-mode: crd
              identity-heartbeat-timeout: "30m0s"
              identity-gc-interval: "15m0s"
              cilium-endpoint-gc-interval: "5m0s"
              nodes-gc-interval: "5m0s"
            
              # If you want to run cilium in debug mode change this value to true
              debug: "false"
              debug-verbose: ""
              # The agent can be put into the following three policy enforcement modes
              # default, always and never.
              # https://docs.cilium.io/en/latest/security/policy/intro/#policy-enforcement-modes
              enable-policy: "default"
              policy-cidr-match-mode: ""
              # If you want metrics enabled in cilium-operator, set the port for
              # which the Cilium Operator will have their metrics exposed.
              # NOTE that this will open the port on the nodes where Cilium operator pod
              # is scheduled.
              operator-prometheus-serve-addr: ":9963"
              enable-metrics: "true"
            
              # Enable IPv4 addressing. If enabled, all endpoints are allocated an IPv4
              # address.
              enable-ipv4: "true"
            
              # Enable IPv6 addressing. If enabled, all endpoints are allocated an IPv6
              # address.
              enable-ipv6: "false"
              # Users who wish to specify their own custom CNI configuration file must set
              # custom-cni-conf to "true", otherwise Cilium may overwrite the configuration.
              custom-cni-conf: "false"
              enable-bpf-clock-probe: "false"
              # If you want cilium monitor to aggregate tracing for packets, set this level
              # to "low", "medium", or "maximum". The higher the level, the less packets
              # that will be seen in monitor output.
              monitor-aggregation: medium
            
              # The monitor aggregation interval governs the typical time between monitor
              # notification events for each allowed connection.
              #
              # Only effective when monitor aggregation is set to "medium" or higher.
              monitor-aggregation-interval: "5s"
            
              # The monitor aggregation flags determine which TCP flags which, upon the
              # first observation, cause monitor notifications to be generated.
              #
              # Only effective when monitor aggregation is set to "medium" or higher.
              monitor-aggregation-flags: all
              # Specifies the ratio (0.0-1.0] of total system memory to use for dynamic
              # sizing of the TCP CT, non-TCP CT, NAT and policy BPF maps.
              bpf-map-dynamic-size-ratio: "0.0025"
              # bpf-policy-map-max specifies the maximum number of entries in endpoint
              # policy map (per endpoint)
              bpf-policy-map-max: "16384"
              # bpf-lb-map-max specifies the maximum number of entries in bpf lb service,
              # backend and affinity maps.
              bpf-lb-map-max: "65536"
              bpf-lb-external-clusterip: "false"
            
              bpf-events-drop-enabled: "true"
              bpf-events-policy-verdict-enabled: "true"
              bpf-events-trace-enabled: "true"
            
              # Pre-allocation of map entries allows per-packet latency to be reduced, at
              # the expense of up-front memory allocation for the entries in the maps. The
              # default value below will minimize memory usage in the default installation;
              # users who are sensitive to latency may consider setting this to "true".
              #
              # This option was introduced in Cilium 1.4. Cilium 1.3 and earlier ignore
              # this option and behave as though it is set to "true".
              #
              # If this value is modified, then during the next Cilium startup the restore
              # of existing endpoints and tracking of ongoing connections may be disrupted.
              # As a result, reply packets may be dropped and the load-balancing decisions
              # for established connections may change.
              #
              # If this option is set to "false" during an upgrade from 1.3 or earlier to
              # 1.4 or later, then it may cause one-time disruptions during the upgrade.
              preallocate-bpf-maps: "false"
            
              # Name of the cluster. Only relevant when building a mesh of clusters.
              cluster-name: default
              # Unique ID of the cluster. Must be unique across all conneted clusters and
              # in the range of 1 and 255. Only relevant when building a mesh of clusters.
              cluster-id: "0"
            
              # Encapsulation mode for communication between nodes
              # Possible values:
              #   - disabled
              #   - vxlan (default)
              #   - geneve
              # Default case
              routing-mode: "tunnel"
              tunnel-protocol: "vxlan"
              service-no-backend-response: "reject"
            
            
              # Enables L7 proxy for L7 policy enforcement and visibility
              enable-l7-proxy: "true"
            
              enable-ipv4-masquerade: "true"
              enable-ipv4-big-tcp: "false"
              enable-ipv6-big-tcp: "false"
              enable-ipv6-masquerade: "true"
              enable-tcx: "true"
              datapath-mode: "veth"
              enable-masquerade-to-route-source: "false"
            
              enable-xt-socket-fallback: "true"
              install-no-conntrack-iptables-rules: "false"
            
              auto-direct-node-routes: "false"
              direct-routing-skip-unreachable: "false"
              enable-local-redirect-policy: "false"
              enable-runtime-device-detection: "true"
            
              kube-proxy-replacement: "true"
              kube-proxy-replacement-healthz-bind-address: ""
              bpf-lb-sock: "false"
              bpf-lb-sock-terminate-pod-connections: "false"
              nodeport-addresses: ""
              enable-health-check-nodeport: "true"
              enable-health-check-loadbalancer-ip: "false"
              node-port-bind-protection: "true"
              enable-auto-protect-node-port-range: "true"
              bpf-lb-acceleration: "disabled"
              enable-svc-source-range-check: "true"
              enable-l2-neigh-discovery: "true"
              arping-refresh-period: "30s"
              k8s-require-ipv4-pod-cidr: "false"
              k8s-require-ipv6-pod-cidr: "false"
              enable-k8s-networkpolicy: "true"
              # Tell the agent to generate and write a CNI configuration file
              write-cni-conf-when-ready: /host/etc/cni/net.d/05-cilium.conflist
              cni-exclusive: "true"
              cni-log-file: "/var/run/cilium/cilium-cni.log"
              enable-endpoint-health-checking: "true"
              enable-health-checking: "true"
              enable-well-known-identities: "false"
              enable-node-selector-labels: "false"
              synchronize-k8s-nodes: "true"
              operator-api-serve-addr: "127.0.0.1:9234"
              ipam: "kubernetes"
              ipam-cilium-node-update-rate: "15s"
              egress-gateway-reconciliation-trigger-interval: "1s"
              enable-vtep: "false"
              vtep-endpoint: ""
              vtep-cidr: ""
              vtep-mask: ""
              vtep-mac: ""
              procfs: "/host/proc"
              bpf-root: "/sys/fs/bpf"
              cgroup-root: "/sys/fs/cgroup"
              enable-k8s-terminating-endpoint: "true"
              enable-sctp: "false"
            
              k8s-client-qps: "10"
              k8s-client-burst: "20"
              remove-cilium-node-taints: "true"
              set-cilium-node-taints: "true"
              set-cilium-is-up-condition: "true"
              unmanaged-pod-watcher-interval: "15"
              # default DNS proxy to transparent mode in non-chaining modes
              dnsproxy-enable-transparent-mode: "true"
              dnsproxy-socket-linger-timeout: "10"
              tofqdns-dns-reject-response-code: "refused"
              tofqdns-enable-dns-compression: "true"
              tofqdns-endpoint-max-ip-per-hostname: "50"
              tofqdns-idle-connection-grace-period: "0s"
              tofqdns-max-deferred-connection-deletes: "10000"
              tofqdns-proxy-response-max-delay: "100ms"
              agent-not-ready-taint-key: "node.cilium.io/agent-not-ready"
            
              mesh-auth-enabled: "true"
              mesh-auth-queue-size: "1024"
              mesh-auth-rotated-identities-queue-size: "1024"
              mesh-auth-gc-interval: "5m0s"
            
              proxy-xff-num-trusted-hops-ingress: "0"
              proxy-xff-num-trusted-hops-egress: "0"
              proxy-connect-timeout: "2"
              proxy-max-requests-per-connection: "0"
              proxy-max-connection-duration-seconds: "0"
              proxy-idle-timeout-seconds: "60"
            
              external-envoy-proxy: "true"
              envoy-base-id: "0"
            
              envoy-keep-cap-netbindservice: "false"
              max-connected-clusters: "255"
              clustermesh-enable-endpoint-sync: "false"
              clustermesh-enable-mcs-api: "false"
            
              nat-map-stats-entries: "32"
              nat-map-stats-interval: "30s"
            
            # Extra config allows adding arbitrary properties to the cilium config.
            # By putting it at the end of the ConfigMap, it's also possible to override existing properties.
            ---
            # Source: cilium/templates/cilium-envoy/configmap.yaml
            apiVersion: v1
            kind: ConfigMap
            metadata:
              name: cilium-envoy-config
              namespace: kube-system
            data:
              bootstrap-config.json: |
                {
                  "node": {
                    "id": "host~127.0.0.1~no-id~localdomain",
                    "cluster": "ingress-cluster"
                  },
                  "staticResources": {
                    "listeners": [
                      {
                        "name": "envoy-prometheus-metrics-listener",
                        "address": {
                          "socket_address": {
                            "address": "0.0.0.0",
                            "port_value": 9964
                          }
                        },
                        "filter_chains": [
                          {
                            "filters": [
                              {
                                "name": "envoy.filters.network.http_connection_manager",
                                "typed_config": {
                                  "@type": "type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager",
                                  "stat_prefix": "envoy-prometheus-metrics-listener",
                                  "route_config": {
                                    "virtual_hosts": [
                                      {
                                        "name": "prometheus_metrics_route",
                                        "domains": [
                                          "*"
                                        ],
                                        "routes": [
                                          {
                                            "name": "prometheus_metrics_route",
                                            "match": {
                                              "prefix": "/metrics"
                                            },
                                            "route": {
                                              "cluster": "/envoy-admin",
                                              "prefix_rewrite": "/stats/prometheus"
                                            }
                                          }
                                        ]
                                      }
                                    ]
                                  },
                                  "http_filters": [
                                    {
                                      "name": "envoy.filters.http.router",
                                      "typed_config": {
                                        "@type": "type.googleapis.com/envoy.extensions.filters.http.router.v3.Router"
                                      }
                                    }
                                  ],
                                  "stream_idle_timeout": "0s"
                                }
                              }
                            ]
                          }
                        ]
                      },
                      {
                        "name": "envoy-health-listener",
                        "address": {
                          "socket_address": {
                            "address": "127.0.0.1",
                            "port_value": 9878
                          }
                        },
                        "filter_chains": [
                          {
                            "filters": [
                              {
                                "name": "envoy.filters.network.http_connection_manager",
                                "typed_config": {
                                  "@type": "type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager",
                                  "stat_prefix": "envoy-health-listener",
                                  "route_config": {
                                    "virtual_hosts": [
                                      {
                                        "name": "health",
                                        "domains": [
                                          "*"
                                        ],
                                        "routes": [
                                          {
                                            "name": "health",
                                            "match": {
                                              "prefix": "/healthz"
                                            },
                                            "route": {
                                              "cluster": "/envoy-admin",
                                              "prefix_rewrite": "/ready"
                                            }
                                          }
                                        ]
                                      }
                                    ]
                                  },
                                  "http_filters": [
                                    {
                                      "name": "envoy.filters.http.router",
                                      "typed_config": {
                                        "@type": "type.googleapis.com/envoy.extensions.filters.http.router.v3.Router"
                                      }
                                    }
                                  ],
                                  "stream_idle_timeout": "0s"
                                }
                              }
                            ]
                          }
                        ]
                      }
                    ],
                    "clusters": [
                      {
                        "name": "ingress-cluster",
                        "type": "ORIGINAL_DST",
                        "connectTimeout": "2s",
                        "lbPolicy": "CLUSTER_PROVIDED",
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "commonHttpProtocolOptions": {
                              "idleTimeout": "60s",
                              "maxConnectionDuration": "0s",
                              "maxRequestsPerConnection": 0
                            },
                            "useDownstreamProtocolConfig": {}
                          }
                        },
                        "cleanupInterval": "2.500s"
                      },
                      {
                        "name": "egress-cluster-tls",
                        "type": "ORIGINAL_DST",
                        "connectTimeout": "2s",
                        "lbPolicy": "CLUSTER_PROVIDED",
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "commonHttpProtocolOptions": {
                              "idleTimeout": "60s",
                              "maxConnectionDuration": "0s",
                              "maxRequestsPerConnection": 0
                            },
                            "upstreamHttpProtocolOptions": {},
                            "useDownstreamProtocolConfig": {}
                          }
                        },
                        "cleanupInterval": "2.500s",
                        "transportSocket": {
                          "name": "cilium.tls_wrapper",
                          "typedConfig": {
                            "@type": "type.googleapis.com/cilium.UpstreamTlsWrapperContext"
                          }
                        }
                      },
                      {
                        "name": "egress-cluster",
                        "type": "ORIGINAL_DST",
                        "connectTimeout": "2s",
                        "lbPolicy": "CLUSTER_PROVIDED",
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "commonHttpProtocolOptions": {
                              "idleTimeout": "60s",
                              "maxConnectionDuration": "0s",
                              "maxRequestsPerConnection": 0
                            },
                            "useDownstreamProtocolConfig": {}
                          }
                        },
                        "cleanupInterval": "2.500s"
                      },
                      {
                        "name": "ingress-cluster-tls",
                        "type": "ORIGINAL_DST",
                        "connectTimeout": "2s",
                        "lbPolicy": "CLUSTER_PROVIDED",
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "commonHttpProtocolOptions": {
                              "idleTimeout": "60s",
                              "maxConnectionDuration": "0s",
                              "maxRequestsPerConnection": 0
                            },
                            "upstreamHttpProtocolOptions": {},
                            "useDownstreamProtocolConfig": {}
                          }
                        },
                        "cleanupInterval": "2.500s",
                        "transportSocket": {
                          "name": "cilium.tls_wrapper",
                          "typedConfig": {
                            "@type": "type.googleapis.com/cilium.UpstreamTlsWrapperContext"
                          }
                        }
                      },
                      {
                        "name": "xds-grpc-cilium",
                        "type": "STATIC",
                        "connectTimeout": "2s",
                        "loadAssignment": {
                          "clusterName": "xds-grpc-cilium",
                          "endpoints": [
                            {
                              "lbEndpoints": [
                                {
                                  "endpoint": {
                                    "address": {
                                      "pipe": {
                                        "path": "/var/run/cilium/envoy/sockets/xds.sock"
                                      }
                                    }
                                  }
                                }
                              ]
                            }
                          ]
                        },
                        "typedExtensionProtocolOptions": {
                          "envoy.extensions.upstreams.http.v3.HttpProtocolOptions": {
                            "@type": "type.googleapis.com/envoy.extensions.upstreams.http.v3.HttpProtocolOptions",
                            "explicitHttpConfig": {
                              "http2ProtocolOptions": {}
                            }
                          }
                        }
                      },
                      {
                        "name": "/envoy-admin",
                        "type": "STATIC",
                        "connectTimeout": "2s",
                        "loadAssignment": {
                          "clusterName": "/envoy-admin",
                          "endpoints": [
                            {
                              "lbEndpoints": [
                                {
                                  "endpoint": {
                                    "address": {
                                      "pipe": {
                                        "path": "/var/run/cilium/envoy/sockets/admin.sock"
                                      }
                                    }
                                  }
                                }
                              ]
                            }
                          ]
                        }
                      }
                    ]
                  },
                  "dynamicResources": {
                    "ldsConfig": {
                      "apiConfigSource": {
                        "apiType": "GRPC",
                        "transportApiVersion": "V3",
                        "grpcServices": [
                          {
                            "envoyGrpc": {
                              "clusterName": "xds-grpc-cilium"
                            }
                          }
                        ],
                        "setNodeOnFirstMessageOnly": true
                      },
                      "resourceApiVersion": "V3"
                    },
                    "cdsConfig": {
                      "apiConfigSource": {
                        "apiType": "GRPC",
                        "transportApiVersion": "V3",
                        "grpcServices": [
                          {
                            "envoyGrpc": {
                              "clusterName": "xds-grpc-cilium"
                            }
                          }
                        ],
                        "setNodeOnFirstMessageOnly": true
                      },
                      "resourceApiVersion": "V3"
                    }
                  },
                  "bootstrapExtensions": [
                    {
                      "name": "envoy.bootstrap.internal_listener",
                      "typed_config": {
                        "@type": "type.googleapis.com/envoy.extensions.bootstrap.internal_listener.v3.InternalListener"
                      }
                    }
                  ],
                  "layeredRuntime": {
                    "layers": [
                      {
                        "name": "static_layer_0",
                        "staticLayer": {
                          "overload": {
                            "global_downstream_max_connections": 50000
                          }
                        }
                      }
                    ]
                  },
                  "admin": {
                    "address": {
                      "pipe": {
                        "path": "/var/run/cilium/envoy/sockets/admin.sock"
                      }
                    }
                  }
                }
            ---
            # Source: cilium/templates/cilium-agent/clusterrole.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: cilium
              labels:
                app.kubernetes.io/part-of: cilium
            rules:
            - apiGroups:
              - networking.k8s.io
              resources:
              - networkpolicies
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - discovery.k8s.io
              resources:
              - endpointslices
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - ""
              resources:
              - namespaces
              - services
              - pods
              - endpoints
              - nodes
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - apiextensions.k8s.io
              resources:
              - customresourcedefinitions
              verbs:
              - list
              - watch
              # This is used when validating policies in preflight. This will need to stay
              # until we figure out how to avoid "get" inside the preflight, and then
              # should be removed ideally.
              - get
            - apiGroups:
              - cilium.io
              resources:
              - ciliumloadbalancerippools
              - ciliumbgppeeringpolicies
              - ciliumbgpnodeconfigs
              - ciliumbgpadvertisements
              - ciliumbgppeerconfigs
              - ciliumclusterwideenvoyconfigs
              - ciliumclusterwidenetworkpolicies
              - ciliumegressgatewaypolicies
              - ciliumendpoints
              - ciliumendpointslices
              - ciliumenvoyconfigs
              - ciliumidentities
              - ciliumlocalredirectpolicies
              - ciliumnetworkpolicies
              - ciliumnodes
              - ciliumnodeconfigs
              - ciliumcidrgroups
              - ciliuml2announcementpolicies
              - ciliumpodippools
              verbs:
              - list
              - watch
            - apiGroups:
              - cilium.io
              resources:
              - ciliumidentities
              - ciliumendpoints
              - ciliumnodes
              verbs:
              - create
            - apiGroups:
              - cilium.io
              # To synchronize garbage collection of such resources
              resources:
              - ciliumidentities
              verbs:
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumendpoints
              verbs:
              - delete
              - get
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnodes
              - ciliumnodes/status
              verbs:
              - get
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumendpoints/status
              - ciliumendpoints
              - ciliuml2announcementpolicies/status
              - ciliumbgpnodeconfigs/status
              verbs:
              - patch
            ---
            # Source: cilium/templates/cilium-operator/clusterrole.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRole
            metadata:
              name: cilium-operator
              labels:
                app.kubernetes.io/part-of: cilium
            rules:
            - apiGroups:
              - ""
              resources:
              - pods
              verbs:
              - get
              - list
              - watch
              # to automatically delete [core|kube]dns pods so that are starting to being
              # managed by Cilium
              - delete
            - apiGroups:
              - ""
              resources:
              - nodes
              verbs:
              - list
              - watch
            - apiGroups:
              - ""
              resources:
              # To remove node taints
              - nodes
              # To set NetworkUnavailable false on startup
              - nodes/status
              verbs:
              - patch
            - apiGroups:
              - discovery.k8s.io
              resources:
              - endpointslices
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - ""
              resources:
              # to perform LB IP allocation for BGP
              - services/status
              verbs:
              - update
              - patch
            - apiGroups:
              - ""
              resources:
              # to check apiserver connectivity
              - namespaces
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - ""
              resources:
              # to perform the translation of a CNP that contains `ToGroup` to its endpoints
              - services
              - endpoints
              verbs:
              - get
              - list
              - watch
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnetworkpolicies
              - ciliumclusterwidenetworkpolicies
              verbs:
              # Create auto-generated CNPs and CCNPs from Policies that have 'toGroups'
              - create
              - update
              - deletecollection
              # To update the status of the CNPs and CCNPs
              - patch
              - get
              - list
              - watch
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnetworkpolicies/status
              - ciliumclusterwidenetworkpolicies/status
              verbs:
              # Update the auto-generated CNPs and CCNPs status.
              - patch
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumendpoints
              - ciliumidentities
              verbs:
              # To perform garbage collection of such resources
              - delete
              - list
              - watch
            - apiGroups:
              - cilium.io
              resources:
              - ciliumidentities
              verbs:
              # To synchronize garbage collection of such resources
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnodes
              verbs:
              - create
              - update
              - get
              - list
              - watch
                # To perform CiliumNode garbage collector
              - delete
            - apiGroups:
              - cilium.io
              resources:
              - ciliumnodes/status
              verbs:
              - update
            - apiGroups:
              - cilium.io
              resources:
              - ciliumendpointslices
              - ciliumenvoyconfigs
              - ciliumbgppeerconfigs
              - ciliumbgpadvertisements
              - ciliumbgpnodeconfigs
              verbs:
              - create
              - update
              - get
              - list
              - watch
              - delete
              - patch
            - apiGroups:
              - apiextensions.k8s.io
              resources:
              - customresourcedefinitions
              verbs:
              - create
              - get
              - list
              - watch
            - apiGroups:
              - apiextensions.k8s.io
              resources:
              - customresourcedefinitions
              verbs:
              - update
              resourceNames:
              - ciliumloadbalancerippools.cilium.io
              - ciliumbgppeeringpolicies.cilium.io
              - ciliumbgpclusterconfigs.cilium.io
              - ciliumbgppeerconfigs.cilium.io
              - ciliumbgpadvertisements.cilium.io
              - ciliumbgpnodeconfigs.cilium.io
              - ciliumbgpnodeconfigoverrides.cilium.io
              - ciliumclusterwideenvoyconfigs.cilium.io
              - ciliumclusterwidenetworkpolicies.cilium.io
              - ciliumegressgatewaypolicies.cilium.io
              - ciliumendpoints.cilium.io
              - ciliumendpointslices.cilium.io
              - ciliumenvoyconfigs.cilium.io
              - ciliumexternalworkloads.cilium.io
              - ciliumidentities.cilium.io
              - ciliumlocalredirectpolicies.cilium.io
              - ciliumnetworkpolicies.cilium.io
              - ciliumnodes.cilium.io
              - ciliumnodeconfigs.cilium.io
              - ciliumcidrgroups.cilium.io
              - ciliuml2announcementpolicies.cilium.io
              - ciliumpodippools.cilium.io
            - apiGroups:
              - cilium.io
              resources:
              - ciliumloadbalancerippools
              - ciliumpodippools
              - ciliumbgppeeringpolicies
              - ciliumbgpclusterconfigs
              - ciliumbgpnodeconfigoverrides
              verbs:
              - get
              - list
              - watch
            - apiGroups:
                - cilium.io
              resources:
                - ciliumpodippools
              verbs:
                - create
            - apiGroups:
              - cilium.io
              resources:
              - ciliumloadbalancerippools/status
              verbs:
              - patch
            # For cilium-operator running in HA mode.
            #
            # Cilium operator running in HA mode requires the use of ResourceLock for Leader Election
            # between multiple running instances.
            # The preferred way of doing this is to use LeasesResourceLock as edits to Leases are less
            # common and fewer objects in the cluster watch "all Leases".
            - apiGroups:
              - coordination.k8s.io
              resources:
              - leases
              verbs:
              - create
              - get
              - update
            ---
            # Source: cilium/templates/cilium-agent/clusterrolebinding.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              name: cilium
              labels:
                app.kubernetes.io/part-of: cilium
            roleRef:
              apiGroup: rbac.authorization.k8s.io
              kind: ClusterRole
              name: cilium
            subjects:
            - kind: ServiceAccount
              name: "cilium"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-operator/clusterrolebinding.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: ClusterRoleBinding
            metadata:
              name: cilium-operator
              labels:
                app.kubernetes.io/part-of: cilium
            roleRef:
              apiGroup: rbac.authorization.k8s.io
              kind: ClusterRole
              name: cilium-operator
            subjects:
            - kind: ServiceAccount
              name: "cilium-operator"
              namespace: kube-system
            ---
            # Source: cilium/templates/cilium-agent/role.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: Role
            metadata:
              name: cilium-config-agent
              namespace: kube-system
              labels:
                app.kubernetes.io/part-of: cilium
            rules:
            - apiGroups:
              - ""
              resources:
              - configmaps
              verbs:
              - get
              - list
              - watch
            ---
            # Source: cilium/templates/cilium-agent/rolebinding.yaml
            apiVersion: rbac.authorization.k8s.io/v1
            kind: RoleBinding
            metadata:
              name: cilium-config-agent
              namespace: kube-system
              labels:
                app.kubernetes.io/part-of: cilium
            roleRef:
              apiGroup: rbac.authorization.k8s.io
              kind: Role
              name: cilium-config-agent
            subjects:
              - kind: ServiceAccount
                name: "cilium"
                namespace: kube-system
            ---
            # Source: cilium/templates/cilium-agent/daemonset.yaml
            apiVersion: apps/v1
            kind: DaemonSet
            metadata:
              name: cilium
              namespace: kube-system
              labels:
                k8s-app: cilium
                app.kubernetes.io/part-of: cilium
                app.kubernetes.io/name: cilium-agent
            spec:
              selector:
                matchLabels:
                  k8s-app: cilium
              updateStrategy:
                rollingUpdate:
                  maxUnavailable: 2
                type: RollingUpdate
              template:
                metadata:
                  annotations:
                  labels:
                    k8s-app: cilium
                    app.kubernetes.io/name: cilium-agent
                    app.kubernetes.io/part-of: cilium
                spec:
                  securityContext:
                    appArmorProfile:
                      type: Unconfined
                  containers:
                  - name: cilium-agent
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    command:
                    - cilium-agent
                    args:
                    - --config-dir=/tmp/cilium/config-map
                    startupProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9879
                        scheme: HTTP
                        httpHeaders:
                        - name: "brief"
                          value: "true"
                      failureThreshold: 105
                      periodSeconds: 2
                      successThreshold: 1
                      initialDelaySeconds: 5
                    livenessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9879
                        scheme: HTTP
                        httpHeaders:
                        - name: "brief"
                          value: "true"
                      periodSeconds: 30
                      successThreshold: 1
                      failureThreshold: 10
                      timeoutSeconds: 5
                    readinessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9879
                        scheme: HTTP
                        httpHeaders:
                        - name: "brief"
                          value: "true"
                      periodSeconds: 30
                      successThreshold: 1
                      failureThreshold: 3
                      timeoutSeconds: 5
                    env:
                    - name: K8S_NODE_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.nodeName
                    - name: CILIUM_K8S_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: CILIUM_CLUSTERMESH_CONFIG
                      value: /var/lib/cilium/clustermesh/
                    - name: GOMEMLIMIT
                      valueFrom:
                        resourceFieldRef:
                          resource: limits.memory
                          divisor: '1'
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    lifecycle:
                      postStart:
                        exec:
                          command:
                          - "bash"
                          - "-c"
                          - |
                                set -o errexit
                                set -o pipefail
                                set -o nounset
                                
                                # When running in AWS ENI mode, it's likely that 'aws-node' has
                                # had a chance to install SNAT iptables rules. These can result
                                # in dropped traffic, so we should attempt to remove them.
                                # We do it using a 'postStart' hook since this may need to run
                                # for nodes which might have already been init'ed but may still
                                # have dangling rules. This is safe because there are no
                                # dependencies on anything that is part of the startup script
                                # itself, and can be safely run multiple times per node (e.g. in
                                # case of a restart).
                                if [[ "$(iptables-save | grep -E -c 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN')" != "0" ]];
                                then
                                    echo 'Deleting iptables rules created by the AWS CNI VPC plugin'
                                    iptables-save | grep -E -v 'AWS-SNAT-CHAIN|AWS-CONNMARK-CHAIN' | iptables-restore
                                fi
                                echo 'Done!'
                                
                      preStop:
                        exec:
                          command:
                          - /cni-uninstall.sh
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        add:
                          - CHOWN
                          - KILL
                          - NET_ADMIN
                          - NET_RAW
                          - IPC_LOCK
                          - SYS_ADMIN
                          - SYS_RESOURCE
                          - DAC_OVERRIDE
                          - FOWNER
                          - SETGID
                          - SETUID
                        drop:
                          - ALL
                    terminationMessagePolicy: FallbackToLogsOnError
                    volumeMounts:
                    - name: envoy-sockets
                      mountPath: /var/run/cilium/envoy/sockets
                      readOnly: false
                    # Unprivileged containers need to mount /proc/sys/net from the host
                    # to have write access
                    - mountPath: /host/proc/sys/net
                      name: host-proc-sys-net
                    # Unprivileged containers need to mount /proc/sys/kernel from the host
                    # to have write access
                    - mountPath: /host/proc/sys/kernel
                      name: host-proc-sys-kernel
                    - name: bpf-maps
                      mountPath: /sys/fs/bpf
                      # Unprivileged containers can't set mount propagation to bidirectional
                      # in this case we will mount the bpf fs from an init container that
                      # is privileged and set the mount propagation from host to container
                      # in Cilium.
                      mountPropagation: HostToContainer
                    # Check for duplicate mounts before mounting
                    - name: cilium-cgroup
                      mountPath: /sys/fs/cgroup
                    - name: cilium-run
                      mountPath: /var/run/cilium
                    - name: etc-cni-netd
                      mountPath: /host/etc/cni/net.d
                    - name: clustermesh-secrets
                      mountPath: /var/lib/cilium/clustermesh
                      readOnly: true
                      # Needed to be able to load kernel modules
                    - name: lib-modules
                      mountPath: /lib/modules
                      readOnly: true
                    - name: xtables-lock
                      mountPath: /run/xtables.lock
                    - name: tmp
                      mountPath: /tmp
                  initContainers:
                  - name: config
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    command:
                    - cilium-dbg
                    - build-config
                    env:
                    - name: K8S_NODE_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.nodeName
                    - name: CILIUM_K8S_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    volumeMounts:
                    - name: tmp
                      mountPath: /tmp
                    terminationMessagePolicy: FallbackToLogsOnError
                  - name: apply-sysctl-overwrites
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    env:
                    - name: BIN_PATH
                      value: /opt/cni/bin
                    command:
                    - sh
                    - -ec
                    # The statically linked Go program binary is invoked to avoid any
                    # dependency on utilities like sh that can be missing on certain
                    # distros installed on the underlying host. Copy the binary to the
                    # same directory where we install cilium cni plugin so that exec permissions
                    # are available.
                    - |
                      cp /usr/bin/cilium-sysctlfix /hostbin/cilium-sysctlfix;
                      nsenter --mount=/hostproc/1/ns/mnt "${BIN_PATH}/cilium-sysctlfix";
                      rm /hostbin/cilium-sysctlfix
                    volumeMounts:
                    - name: hostproc
                      mountPath: /hostproc
                    - name: cni-path
                      mountPath: /hostbin
                    terminationMessagePolicy: FallbackToLogsOnError
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        add:
                          - SYS_ADMIN
                          - SYS_CHROOT
                          - SYS_PTRACE
                        drop:
                          - ALL
                  # Mount the bpf fs if it is not mounted. We will perform this task
                  # from a privileged container because the mount propagation bidirectional
                  # only works from privileged containers.
                  - name: mount-bpf-fs
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    args:
                    - 'mount | grep "/sys/fs/bpf type bpf" || mount -t bpf bpf /sys/fs/bpf'
                    command:
                    - /bin/bash
                    - -c
                    - --
                    terminationMessagePolicy: FallbackToLogsOnError
                    securityContext:
                      privileged: true
                    volumeMounts:
                    - name: bpf-maps
                      mountPath: /sys/fs/bpf
                      mountPropagation: Bidirectional
                  - name: clean-cilium-state
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    command:
                    - /init-container.sh
                    env:
                    - name: CILIUM_ALL_STATE
                      valueFrom:
                        configMapKeyRef:
                          name: cilium-config
                          key: clean-cilium-state
                          optional: true
                    - name: CILIUM_BPF_STATE
                      valueFrom:
                        configMapKeyRef:
                          name: cilium-config
                          key: clean-cilium-bpf-state
                          optional: true
                    - name: WRITE_CNI_CONF_WHEN_READY
                      valueFrom:
                        configMapKeyRef:
                          name: cilium-config
                          key: write-cni-conf-when-ready
                          optional: true
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    terminationMessagePolicy: FallbackToLogsOnError
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        add:
                          - NET_ADMIN
                          - SYS_ADMIN
                          - SYS_RESOURCE
                        drop:
                          - ALL
                    volumeMounts:
                    - name: bpf-maps
                      mountPath: /sys/fs/bpf
                      # Required to mount cgroup filesystem from the host to cilium agent pod
                    - name: cilium-cgroup
                      mountPath: /sys/fs/cgroup
                      mountPropagation: HostToContainer
                    - name: cilium-run
                      mountPath: /var/run/cilium # wait-for-kube-proxy
                  # Install the CNI binaries in an InitContainer so we don't have a writable host mount in the agent
                  - name: install-cni-binaries
                    image: "quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39"
                    imagePullPolicy: IfNotPresent
                    command:
                      - "/install-plugin.sh"
                    resources:
                      requests:
                        cpu: 100m
                        memory: 10Mi
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        drop:
                          - ALL
                    terminationMessagePolicy: FallbackToLogsOnError
                    volumeMounts:
                      - name: cni-path
                        mountPath: /host/opt/cni/bin # .Values.cni.install
                  restartPolicy: Always
                  priorityClassName: system-node-critical
                  serviceAccountName: "cilium"
                  automountServiceAccountToken: true
                  terminationGracePeriodSeconds: 1
                  hostNetwork: true
                  affinity:
                    podAntiAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                      - labelSelector:
                          matchLabels:
                            k8s-app: cilium
                        topologyKey: kubernetes.io/hostname
                  nodeSelector:
                    kubernetes.io/os: linux
                  tolerations:
                    - operator: Exists
                  volumes:
                    # For sharing configuration between the "config" initContainer and the agent
                  - name: tmp
                    emptyDir: {}
                    # To keep state between restarts / upgrades
                  - name: cilium-run
                    hostPath:
                      path: /var/run/cilium
                      type: DirectoryOrCreate
                    # To keep state between restarts / upgrades for bpf maps
                  - name: bpf-maps
                    hostPath:
                      path: /sys/fs/bpf
                      type: DirectoryOrCreate
                  # To mount cgroup2 filesystem on the host or apply sysctlfix
                  - name: hostproc
                    hostPath:
                      path: /proc
                      type: Directory
                  # To keep state between restarts / upgrades for cgroup2 filesystem
                  - name: cilium-cgroup
                    hostPath:
                      path: /sys/fs/cgroup
                      type: DirectoryOrCreate
                  # To install cilium cni plugin in the host
                  - name: cni-path
                    hostPath:
                      path:  /opt/cni/bin
                      type: DirectoryOrCreate
                    # To install cilium cni configuration in the host
                  - name: etc-cni-netd
                    hostPath:
                      path: /etc/cni/net.d
                      type: DirectoryOrCreate
                    # To be able to load kernel modules
                  - name: lib-modules
                    hostPath:
                      path: /lib/modules
                    # To access iptables concurrently with other processes (e.g. kube-proxy)
                  - name: xtables-lock
                    hostPath:
                      path: /run/xtables.lock
                      type: FileOrCreate
                  # Sharing socket with Cilium Envoy on the same node by using a host path
                  - name: envoy-sockets
                    hostPath:
                      path: "/var/run/cilium/envoy/sockets"
                      type: DirectoryOrCreate
                    # To read the clustermesh configuration
                  - name: clustermesh-secrets
                    projected:
                      # note: the leading zero means this number is in octal representation: do not remove it
                      defaultMode: 0400
                      sources:
                      - secret:
                          name: cilium-clustermesh
                          optional: true
                          # note: items are not explicitly listed here, since the entries of this secret
                          # depend on the peers configured, and that would cause a restart of all agents
                          # at every addition/removal. Leaving the field empty makes each secret entry
                          # to be automatically projected into the volume as a file whose name is the key.
                      - secret:
                          name: clustermesh-apiserver-remote-cert
                          optional: true
                          items:
                          - key: tls.key
                            path: common-etcd-client.key
                          - key: tls.crt
                            path: common-etcd-client.crt
                          - key: ca.crt
                            path: common-etcd-client-ca.crt
                      # note: we configure the volume for the kvstoremesh-specific certificate
                      # regardless of whether KVStoreMesh is enabled or not, so that it can be
                      # automatically mounted in case KVStoreMesh gets subsequently enabled,
                      # without requiring an agent restart.
                      - secret:
                          name: clustermesh-apiserver-local-cert
                          optional: true
                          items:
                          - key: tls.key
                            path: local-etcd-client.key
                          - key: tls.crt
                            path: local-etcd-client.crt
                          - key: ca.crt
                            path: local-etcd-client-ca.crt
                  - name: host-proc-sys-net
                    hostPath:
                      path: /proc/sys/net
                      type: Directory
                  - name: host-proc-sys-kernel
                    hostPath:
                      path: /proc/sys/kernel
                      type: Directory
            ---
            # Source: cilium/templates/cilium-envoy/daemonset.yaml
            apiVersion: apps/v1
            kind: DaemonSet
            metadata:
              name: cilium-envoy
              namespace: kube-system
              labels:
                k8s-app: cilium-envoy
                app.kubernetes.io/part-of: cilium
                app.kubernetes.io/name: cilium-envoy
                name: cilium-envoy
            spec:
              selector:
                matchLabels:
                  k8s-app: cilium-envoy
              updateStrategy:
                rollingUpdate:
                  maxUnavailable: 2
                type: RollingUpdate
              template:
                metadata:
                  annotations:
                    prometheus.io/port: "9964"
                    prometheus.io/scrape: "true"
                  labels:
                    k8s-app: cilium-envoy
                    name: cilium-envoy
                    app.kubernetes.io/name: cilium-envoy
                    app.kubernetes.io/part-of: cilium
                spec:
                  securityContext:
                    appArmorProfile:
                      type: Unconfined
                  containers:
                  - name: cilium-envoy
                    image: "quay.io/cilium/cilium-envoy:v1.29.7-39a2a56bbd5b3a591f69dbca51d3e30ef97e0e51@sha256:bd5ff8c66716080028f414ec1cb4f7dc66f40d2fb5a009fff187f4a9b90b566b"
                    imagePullPolicy: IfNotPresent
                    command:
                    - /usr/bin/cilium-envoy-starter
                    args:
                    - '--'
                    - '-c /var/run/cilium/envoy/bootstrap-config.json'
                    - '--base-id 0'
                    - '--log-level info'
                    - '--log-format [%Y-%m-%d %T.%e][%t][%l][%n] [%g:%#] %v'
                    startupProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9878
                        scheme: HTTP
                      failureThreshold: 105
                      periodSeconds: 2
                      successThreshold: 1
                      initialDelaySeconds: 5
                    livenessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9878
                        scheme: HTTP
                      periodSeconds: 30
                      successThreshold: 1
                      failureThreshold: 10
                      timeoutSeconds: 5
                    readinessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9878
                        scheme: HTTP
                      periodSeconds: 30
                      successThreshold: 1
                      failureThreshold: 3
                      timeoutSeconds: 5
                    env:
                    - name: K8S_NODE_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.nodeName
                    - name: CILIUM_K8S_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    ports:
                    - name: envoy-metrics
                      containerPort: 9964
                      hostPort: 9964
                      protocol: TCP
                    securityContext:
                      seLinuxOptions:
                        level: s0
                        type: spc_t
                      capabilities:
                        add:
                          - NET_ADMIN
                          - SYS_ADMIN
                        drop:
                          - ALL
                    terminationMessagePolicy: FallbackToLogsOnError
                    volumeMounts:
                    - name: envoy-sockets
                      mountPath: /var/run/cilium/envoy/sockets
                      readOnly: false
                    - name: envoy-artifacts
                      mountPath: /var/run/cilium/envoy/artifacts
                      readOnly: true
                    - name: envoy-config
                      mountPath: /var/run/cilium/envoy/
                      readOnly: true
                    - name: bpf-maps
                      mountPath: /sys/fs/bpf
                      mountPropagation: HostToContainer
                  restartPolicy: Always
                  priorityClassName: system-node-critical
                  serviceAccountName: "cilium-envoy"
                  automountServiceAccountToken: true
                  terminationGracePeriodSeconds: 1
                  hostNetwork: true
                  affinity:
                    nodeAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                        nodeSelectorTerms:
                        - matchExpressions:
                          - key: cilium.io/no-schedule
                            operator: NotIn
                            values:
                            - "true"
                    podAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                      - labelSelector:
                          matchLabels:
                            k8s-app: cilium
                        topologyKey: kubernetes.io/hostname
                    podAntiAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                      - labelSelector:
                          matchLabels:
                            k8s-app: cilium-envoy
                        topologyKey: kubernetes.io/hostname
                  nodeSelector:
                    kubernetes.io/os: linux
                  tolerations:
                    - operator: Exists
                  volumes:
                  - name: envoy-sockets
                    hostPath:
                      path: "/var/run/cilium/envoy/sockets"
                      type: DirectoryOrCreate
                  - name: envoy-artifacts
                    hostPath:
                      path: "/var/run/cilium/envoy/artifacts"
                      type: DirectoryOrCreate
                  - name: envoy-config
                    configMap:
                      name: cilium-envoy-config
                      # note: the leading zero means this number is in octal representation: do not remove it
                      defaultMode: 0400
                      items:
                        - key: bootstrap-config.json
                          path: bootstrap-config.json
                    # To keep state between restarts / upgrades
                    # To keep state between restarts / upgrades for bpf maps
                  - name: bpf-maps
                    hostPath:
                      path: /sys/fs/bpf
                      type: DirectoryOrCreate
            ---
            # Source: cilium/templates/cilium-operator/deployment.yaml
            apiVersion: apps/v1
            kind: Deployment
            metadata:
              name: cilium-operator
              namespace: kube-system
              labels:
                io.cilium/app: operator
                name: cilium-operator
                app.kubernetes.io/part-of: cilium
                app.kubernetes.io/name: cilium-operator
            spec:
              # See docs on ServerCapabilities.LeasesResourceLock in file pkg/k8s/version/version.go
              # for more details.
              # Note: Set to 2 for production HA. Kubernetes will schedule based on available nodes and anti-affinity rules.
              replicas: 2
              selector:
                matchLabels:
                  io.cilium/app: operator
                  name: cilium-operator
              # ensure operator update on single node k8s clusters, by using rolling update with maxUnavailable=100% in case
              # of one replica and no user configured Recreate strategy.
              # otherwise an update might get stuck due to the default maxUnavailable=50% in combination with the
              # podAntiAffinity which prevents deployments of multiple operator replicas on the same node.
              strategy:
                rollingUpdate:
                  maxSurge: 25%
                  maxUnavailable: 50%
                type: RollingUpdate
              template:
                metadata:
                  annotations:
                    prometheus.io/port: "9963"
                    prometheus.io/scrape: "true"
                  labels:
                    io.cilium/app: operator
                    name: cilium-operator
                    app.kubernetes.io/part-of: cilium
                    app.kubernetes.io/name: cilium-operator
                spec:
                  containers:
                  - name: cilium-operator
                    image: "quay.io/cilium/operator-generic:v1.16.1@sha256:3bc7e7a43bc4a4d8989cb7936c5d96675dd2d02c306adf925ce0a7c35aa27dc4"
                    imagePullPolicy: IfNotPresent
                    command:
                    - cilium-operator-generic
                    args:
                    - --config-dir=/tmp/cilium/config-map
                    - --debug=$(CILIUM_DEBUG)
                    env:
                    - name: K8S_NODE_NAME
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: spec.nodeName
                    - name: CILIUM_K8S_NAMESPACE
                      valueFrom:
                        fieldRef:
                          apiVersion: v1
                          fieldPath: metadata.namespace
                    - name: CILIUM_DEBUG
                      valueFrom:
                        configMapKeyRef:
                          key: debug
                          name: cilium-config
                          optional: true
                    - name: KUBERNETES_SERVICE_HOST
                      value: "localhost"
                    - name: KUBERNETES_SERVICE_PORT
                      value: "7445"
                    ports:
                    - name: prometheus
                      containerPort: 9963
                      protocol: TCP
                    livenessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9234
                        scheme: HTTP
                      initialDelaySeconds: 60
                      periodSeconds: 10
                      timeoutSeconds: 3
                    readinessProbe:
                      httpGet:
                        host: "127.0.0.1"
                        path: /healthz
                        port: 9234
                        scheme: HTTP
                      initialDelaySeconds: 0
                      periodSeconds: 5
                      timeoutSeconds: 3
                      failureThreshold: 5
                    volumeMounts:
                    - name: cilium-config-path
                      mountPath: /tmp/cilium/config-map
                      readOnly: true
                    terminationMessagePolicy: FallbackToLogsOnError
                  hostNetwork: true
                  restartPolicy: Always
                  priorityClassName: system-cluster-critical
                  serviceAccountName: "cilium-operator"
                  automountServiceAccountToken: true
                  # In HA mode, cilium-operator pods must not be scheduled on the same
                  # node as they will clash with each other.
                  affinity:
                    podAntiAffinity:
                      requiredDuringSchedulingIgnoredDuringExecution:
                      - labelSelector:
                          matchLabels:
                            io.cilium/app: operator
                        topologyKey: kubernetes.io/hostname
                  nodeSelector:
                    kubernetes.io/os: linux
                  tolerations:
                    - operator: Exists
                  volumes:
                    # To read the configuration from the config map
                  - name: cilium-config-path
                    configMap:
                      name: cilium-config
    # Cilium CNI for bootstrap - minimal config
    # ArgoCD will adopt and enable full features (Hubble, Gateway API)
    extraManifests: []
    #   - https://www.example.com/manifest1.yaml
    #   - https://www.example.com/manifest2.yaml

    # A list of inline Kubernetes manifests.
