# Architecture Decision: EventDrivenService Platform API

**Status:** Proposed
**Date:** 2025-12-08
**Deciders:** Platform Team
**Reference Implementation:** `bizmatters/services/agent_executor/`

---

## Context

We successfully deployed the agent-executor service using direct Kubernetes manifests (Deployment + Service + KEDA ScaledObject). The deployment is production-ready and all verification checks pass. However, we anticipate deploying additional NATS-based event-driven services in the future.

**Current Approach:**
- 212 lines of explicit Kubernetes YAML per service
- Pattern: NATS consumer → KEDA autoscaling → Init container migrations
- Working perfectly for agent-executor

**Problem:**
- Repetitive boilerplate for each new NATS-based service
- No standardization of NATS worker deployment patterns
- Copy-paste errors likely when deploying service #2, #3, etc.

**Opportunity:**
- Create reusable EventDrivenService platform API (Crossplane XRD + Composition)
- Abstract the deployment pattern, not the application logic
- Reduce future service deployments from 212 lines to ~30 lines

---

## Zero-Touch Platform Constraints

### Non-Negotiable Principles

1. **Crash-Only Recovery**: Entire state reconstructible from Git in <30 minutes
2. **GitOps-Native**: All changes via Git commits, ArgoCD auto-syncs
3. **No Manual Secret Management**: Secrets auto-generated by Crossplane or synced by ESO
4. **Immutable Infrastructure**: Talos OS, API-only cluster management
5. **Agent-Compatible Complexity**: Use standard Kubernetes APIs that AI agents understand

### Critical Constraint: Hybrid Secret Sources

**We CANNOT use a single-secret pattern** because secrets come from different sources:

| Secret Source | Owner | Auto-Generated? | Consolidatable? |
|---------------|-------|-----------------|-----------------|
| Database credentials | Crossplane | ✅ Yes | ❌ No |
| Cache credentials | Crossplane | ✅ Yes | ❌ No |
| LLM API keys | ExternalSecrets (SSM) | ✅ Yes | ⚠️ Possible but unnecessary |
| Image registry | ExternalSecrets (SSM) | ✅ Yes | ⚠️ Possible but unnecessary |

**Rationale:**
- Crossplane auto-generates `{resource}-conn` secrets when PostgresInstance/DragonflyInstance claims are created
- We don't control the secret name or structure (defined by Crossplane compositions)
- Consolidating would require additional operators/Jobs to copy secrets (anti-pattern)
- Zero-Touch principle: Accept what Crossplane generates, don't fight it

---

## Decision

Create an **EventDrivenService** platform API that:

### 1. Embraces the Hybrid Secret Approach

**Accept multiple secrets from different sources:**

```yaml
apiVersion: platform.bizmatters.io/v1alpha1
kind: EventDrivenService
metadata:
  name: my-service
  namespace: my-namespace
spec:
  # Container configuration
  image: ghcr.io/org/my-service:v1.0.0
  size: medium  # small, medium, large

  # NATS configuration
  nats:
    url: nats://nats.nats.svc:4222
    stream: MY_STREAM
    consumer: my-service-workers

  # Multiple secrets (hybrid approach)
  secretRefs:
    # Crossplane-generated database secret (optional)
    - name: my-service-db-conn
      env:
        - secretKey: endpoint
          envName: POSTGRES_HOST
        - secretKey: port
          envName: POSTGRES_PORT
        - secretKey: database
          envName: POSTGRES_DB
        - secretKey: username
          envName: POSTGRES_USER
        - secretKey: password
          envName: POSTGRES_PASSWORD

    # Crossplane-generated cache secret (optional)
    - name: my-service-cache-conn
      env:
        - secretKey: endpoint
          envName: DRAGONFLY_HOST
        - secretKey: port
          envName: DRAGONFLY_PORT
        - secretKey: password
          envName: DRAGONFLY_PASSWORD

    # ESO-synced application secrets (optional, bulk mount)
    - name: my-service-llm-keys
      envFrom: true  # Mount all keys as-is

  # Image pull secrets (optional)
  imagePullSecrets:
    - name: ghcr-pull-secret

  # Init container for migrations (optional)
  initContainer:
    command: ["/bin/bash", "-c"]
    args: ["cd /app && ./scripts/ci/run-migrations.sh"]
```

### 2. Composition Responsibilities

**What the Composition CREATES:**
- ✅ Deployment (with init container if specified)
- ✅ Service (ClusterIP, port 8080)
- ✅ KEDA ScaledObject (with `nats-headless` monitoring endpoint)
- ✅ ServiceAccount (for pod identity)

**What the Composition DOES NOT CREATE:**
- ❌ Database claims (consumer creates `PostgresInstance` separately)
- ❌ Cache claims (consumer creates `DragonflyInstance` separately)
- ❌ NATS streams (consumer creates Job separately)
- ❌ Secrets (Crossplane/ESO creates separately)
- ❌ ExternalSecrets (consumer creates separately)

**Rationale:**
- Keep composition focused on deployment pattern, not infrastructure provisioning
- Existing platform APIs (`PostgresInstance`, `DragonflyInstance`) work well
- NATS stream creation is one-time setup, not per-service
- Secrets have different lifecycles and sources

### 3. Size-Based Resource Allocation

Based on proven agent-executor tuning:

| Size | CPU Request | CPU Limit | Memory Request | Memory Limit | Use Case |
|------|-------------|-----------|----------------|--------------|----------|
| **small** | 250m | 1000m | 512Mi | 2Gi | Lightweight workers, low throughput |
| **medium** | 500m | 2000m | 1Gi | 4Gi | Standard workers (agent-executor) |
| **large** | 1000m | 4000m | 2Gi | 8Gi | Heavy processing, high throughput |

### 4. KEDA Autoscaling Configuration

**Learned from debugging agent-executor:**

```yaml
# ScaledObject spec (generated by Composition)
triggers:
  - type: nats-jetstream
    metadata:
      natsServerMonitoringEndpoint: "nats-headless.nats.svc.cluster.local:8222"  # CRITICAL: Use headless service
      account: "$SYS"
      stream: "{{ .spec.nats.stream }}"
      consumer: "{{ .spec.nats.consumer }}"
      lagThreshold: "5"

minReplicaCount: 1
maxReplicaCount: 10
```

**Critical Fix:** Must use `nats-headless` service (exposes port 8222), not `nats` service (only exposes 4222).

### 5. Health and Readiness Probes

**Standard pattern for all event-driven services:**

```yaml
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3

readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
  timeoutSeconds: 3
  failureThreshold: 2
```

**Expectation:** All services must implement `/health` and `/ready` endpoints.

### 6. Init Container Pattern

**Optional, with flexible configuration:**

```yaml
# When specified in claim
initContainer:
  command: ["/bin/bash", "-c"]
  args: ["cd /app && ./scripts/ci/run-migrations.sh"]

# Composition behavior:
# - Uses same image as main container
# - Mounts same secrets as main container
# - Runs before main container starts
# - If init fails, pod never starts (visible in events)
```

**Use cases:**
- Database migrations (agent-executor pattern)
- Schema initialization
- Configuration validation
- Cache warming

---

## Comparison: Before vs After

### Current (agent-executor) - Direct Manifests

```yaml
# 6 separate files, 212 lines total
- namespace.yaml (5 lines)
- postgres-claim.yaml (12 lines)
- dragonfly-claim.yaml (11 lines)
- nats-stream.yaml (45 lines)
- external-secrets/llm-keys-es.yaml (30 lines)
- external-secrets/image-pull-secret-es.yaml (25 lines)
- agent-executor-deployment.yaml (84 lines - Deployment + Service + KEDA)
```

### Proposed - With EventDrivenService API

```yaml
# 5 separate files, ~150 lines total
- namespace.yaml (5 lines)
- postgres-claim.yaml (12 lines)
- dragonfly-claim.yaml (11 lines)
- nats-stream.yaml (45 lines)
- external-secrets/llm-keys-es.yaml (30 lines)
- external-secrets/image-pull-secret-es.yaml (25 lines)
- event-driven-service-claim.yaml (22 lines - REPLACES 84-line deployment file)
```

**Savings:** ~60 lines per service, 70% reduction in deployment complexity

---

## Consequences

### Positive

✅ **Standardization**: All NATS workers follow same deployment pattern
✅ **Reduced boilerplate**: 84 lines → 22 lines for core deployment
✅ **Debugging**: KEDA monitoring endpoint fix applied to all services
✅ **Onboarding**: New services deploy faster, less copy-paste errors
✅ **Maintainability**: Update composition once, all services benefit
✅ **Zero-Touch compliance**: Respects Crossplane/ESO secret generation

### Negative

⚠️ **Abstraction complexity**: Additional layer between claim and resources
⚠️ **Learning curve**: Developers need to understand Crossplane compositions
⚠️ **Debugging difficulty**: Failures happen inside composition (less visible)
⚠️ **Initial investment**: 3-5 days to build and test composition
⚠️ **Not all services fit**: Some services may need custom deployment patterns

### Mitigations

- **Documentation**: Comprehensive examples and troubleshooting guides
- **Gradual adoption**: Keep direct manifests as fallback for complex cases
- **Validation**: Test composition with 2-3 services before standardizing
- **Escape hatch**: Allow `customDeployment` field to override composition

---

## Implementation Scope

### Phase 1: XRD Definition (1-2 days)

- Create `platform/04-apis/definitions/xeventdrivenservices.yaml`
- Define schema with `secretRefs`, `nats`, `size`, `initContainer`
- Document all fields with examples
- Enable `platform/04-apis.yaml` (currently disabled)

### Phase 2: Composition (2-3 days)

- Create `platform/04-apis/compositions/event-driven-service-composition.yaml`
- Implement Deployment, Service, KEDA ScaledObject creation
- Map `size` to resource limits
- Handle optional init container
- Wire multiple `secretRefs` to env vars

### Phase 3: Validation (1 day)

- Migrate agent-executor to use EventDrivenService API
- Compare deployed resources (should be identical)
- Test KEDA autoscaling
- Verify init container migrations
- Ensure all secrets mount correctly

### Phase 4: Documentation (1 day)

- Update `platform/04-apis/README.md`
- Create example claims for different patterns
- Document troubleshooting steps
- Add to deployment guides

**Total Effort:** 5-7 days

---

## When to Implement

**Trigger Conditions:**

1. ✅ **Deploying 2nd NATS-based service** (Rule of Three - implement on 3rd use, defer on 1st)
2. ✅ **Pattern repetition becomes painful** (copy-paste errors, inconsistencies)
3. ✅ **Team expansion** (multiple developers deploying services)
4. ✅ **Standardization required** (compliance, security policies)

**Current Status:** Deferred until 2nd NATS service deployment

---

## Alternative Considered: Helm Chart

### Approach

Create a Helm chart (`charts/event-driven-service/`) instead of Crossplane API.

### Pros
- ✅ Simpler to understand (template-based)
- ✅ Faster to implement (2-3 days vs 5-7 days)
- ✅ More tooling support (helm diff, helm lint)

### Cons
- ❌ Not GitOps-native (requires Helm controller or manual releases)
- ❌ Doesn't integrate with existing platform APIs (PostgresInstance, DragonflyInstance)
- ❌ Less composable (can't mix Helm + Crossplane claims)
- ❌ Breaks Zero-Touch principle (Helm state separate from Git)

### Decision

**Rejected.** Crossplane aligns better with platform architecture and Zero-Touch principles.

---

## Open Questions

### 1. Should composition create NATS stream automatically?

**Current:** Consumer creates NATS stream via Job (one-time setup)

**Alternative:** Composition creates stream via Crossplane Object resource

**Decision:** Keep current approach. Streams are shared infrastructure, not per-service.

### 2. Should we support custom resource limits?

**Current:** Only `size` enum (small, medium, large)

**Alternative:** Allow `resources: {requests: {cpu: 500m}, limits: {cpu: 2000m}}`

**Decision:** Start with `size` only. Add custom resources if needed later (YAGNI).

### 3. Should we support multiple init containers?

**Current:** Single optional init container

**Alternative:** Array of init containers

**Decision:** Start with single. Add array if needed (YAGNI).

---

## References

- **Implementation:** `bizmatters/services/agent_executor/platform/`
- **Verification:** `zerotouch-platform/scripts/bootstrap/14-verify-agent-executor.sh`
- **Database API:** `platform/05-databases/definitions/postgres-xrd.yaml`
- **Original Specs:** `.kiro/specs/agent-executor/agent-executor-platform-api/`
- **KEDA Fix:** Commit `896850b` - NATS headless service endpoint

---

## Approval

**Next Steps:**

1. Review this architecture decision
2. Validate assumptions with 2nd service deployment plan
3. If approved, create detailed requirements document
4. Implement Phase 1 (XRD Definition)
5. Test with agent-executor migration
6. Iterate based on learnings

**Approved by:** _[Pending]_
**Date:** _[Pending]_
